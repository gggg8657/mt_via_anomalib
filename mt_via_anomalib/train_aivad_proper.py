"""
AI-VADì˜ ì˜¬ë°”ë¥¸ í•™ìŠµ ë°©ë²•
Density Estimation ê¸°ë°˜ One-Class Learning
"""

import os
import json
import torch
import cv2
import numpy as np
from pathlib import Path
from anomalib.models.video import AiVad
from anomalib.engine import Engine
from anomalib.data import Avenue
from anomalib.data.utils import VideoTargetFrame
import shutil

def create_proper_video_dataset_from_json(json_path="image_segments.json", target_dir="proper_video_dataset"):
    """JSONì—ì„œ ì •ìƒ í”„ë ˆì„ë“¤ì„ ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜"""
    print(f"ğŸ“ AI-VADìš© ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ ìƒì„±: {json_path}")
    
    # Avenue ë°ì´í„°ì…‹ êµ¬ì¡° ìƒì„±
    train_dir = Path(target_dir) / "train" / "normal"
    train_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"  ğŸ“‚ ì •ìƒ ë¹„ë””ì˜¤ í´ë”: {train_dir}")
    
    # JSON íŒŒì¼ ë¡œë“œ
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            segments = json.load(f)
        print(f"  ğŸ“Š JSON ë¡œë“œ ì™„ë£Œ: {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
    except Exception as e:
        print(f"âŒ JSON ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None
    
    # ì •ìƒ í”„ë ˆì„ë“¤ì„ ë¹„ë””ì˜¤ë¡œ ë³€í™˜
    video_count = 0
    
    for i, segment in enumerate(segments):
        if segment.get('category') == 'normal' and 'images' in segment:
            images = segment['images']
            
            # ê° ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ì—°ì†ëœ í”„ë ˆì„ë“¤ë¡œ ë¹„ë””ì˜¤ ìƒì„±
            if len(images) >= 2:
                video_count += 1
                
                # ë¹„ë””ì˜¤ íŒŒì¼ëª… ìƒì„±
                video_name = f"normal_{video_count:03d}.mp4"
                video_path = train_dir / video_name
                
                try:
                    # ì²« ë²ˆì§¸ í”„ë ˆì„ìœ¼ë¡œ ë¹„ë””ì˜¤ ì •ë³´ íŒŒì•…
                    first_frame = cv2.imread(images[0])
                    if first_frame is not None:
                        height, width = first_frame.shape[:2]
                        
                        # ë¹„ë””ì˜¤ ë¼ì´í„° ìƒì„±
                        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                        out = cv2.VideoWriter(str(video_path), fourcc, 10.0, (width, height))
                        
                        # í”„ë ˆì„ë“¤ì„ ë¹„ë””ì˜¤ë¡œ ì¶”ê°€
                        for img_path in images[:10]:  # ìµœëŒ€ 10í”„ë ˆì„
                            frame = cv2.imread(img_path)
                            if frame is not None:
                                out.write(frame)
                        
                        out.release()
                        
                        if video_count <= 5:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
                            print(f"    ğŸ¬ {video_name} ({len(images)}í”„ë ˆì„)")
                        
                except Exception as e:
                    print(f"    âš ï¸ {video_name} ìƒì„± ì‹¤íŒ¨: {e}")
                    if os.path.exists(video_path):
                        os.remove(video_path)
    
    print(f"  âœ… ìƒì„±ëœ ë¹„ë””ì˜¤: {video_count}ê°œ")
    
    if video_count == 0:
        print("âŒ ìƒì„±ëœ ë¹„ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return None
    
    return str(Path(target_dir).absolute())

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ AI-VAD ì˜¬ë°”ë¥¸ í•™ìŠµ ë°©ë²•")
    print("=" * 50)
    print("ğŸ’¡ í•µì‹¬ ì›ë¦¬:")
    print("   1. Feature Extraction: Flow, Region, Pose, Deep features")
    print("   2. Density Estimation: ì •ìƒ ë°ì´í„°ì˜ ë¶„í¬ í•™ìŠµ")
    print("   3. One-Class Learning: ì •ìƒ ë°ì´í„°ë§Œìœ¼ë¡œ ë¶„í¬ ëª¨ë¸ë§")
    print("   4. No NN Training: ê°€ì¤‘ì¹˜ í•™ìŠµ ì—†ìŒ!")
    print("=" * 50)
    
    # GPU ì„¤ì •
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ–¥ï¸ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    if device == "cuda":
        print(f"GPU: {torch.cuda.get_device_name()}")
    
    # 1. ë¹„ë””ì˜¤ ë°ì´í„°ì…‹ ìƒì„±
    dataset_root = create_proper_video_dataset_from_json()
    if dataset_root is None:
        print("âŒ ë¹„ë””ì˜¤ ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨")
        return
    
    # 2. AI-VAD ëª¨ë¸ ìƒì„±
    print(f"\nğŸ¤– AI-VAD ëª¨ë¸ ìƒì„±...")
    try:
        model = AiVad(
            # Feature ì¶”ì¶œ ì„¤ì •
            use_velocity_features=True,
            use_pose_features=True,
            use_deep_features=True,
            # Density estimation ì„¤ì •
            n_components_velocity=2,
            n_neighbors_pose=1,
            n_neighbors_deep=1,
        )
        print("âœ… AI-VAD ëª¨ë¸ ìƒì„± ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ AI-VAD ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return
    
    # 3. ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ (ì„ íƒì‚¬í•­)
    checkpoint_path = "aivad_proper_checkpoint.ckpt"
    if os.path.exists(checkpoint_path):
        print(f"\nğŸ”„ ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ: {checkpoint_path}")
        try:
            checkpoint = torch.load(checkpoint_path, weights_only=False)
            if 'state_dict' in checkpoint:
                model.load_state_dict(checkpoint['state_dict'], strict=False)
                print("âœ… ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ")
            else:
                print("âš ï¸ state_dictê°€ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # 4. Anomalib Engine ìƒì„± (AI-VAD ì „ìš© ì„¤ì •)
    print(f"\nğŸ”§ Anomalib Engine ìƒì„±...")
    try:
        engine = Engine(
            devices=1 if device == "cuda" else "auto",
            accelerator="gpu" if device == "cuda" else "cpu",
            precision="32",  # AI-VADëŠ” 32bit ì‚¬ìš©
            # AI-VAD ì „ìš© ì„¤ì •
            max_epochs=1,  # AI-VADëŠ” 1 ì—í¬í¬ë§Œ
            gradient_clip_val=0,  # Gradient clipping ì—†ìŒ
            log_every_n_steps=1,
            enable_progress_bar=True,
            enable_model_summary=False,  # ëª¨ë¸ ìš”ì•½ ë¹„í™œì„±í™”
            num_sanity_val_steps=0,  # ê²€ì¦ ë‹¨ê³„ ì—†ìŒ
        )
        
        print("âœ… Engine ìƒì„± ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ Engine ìƒì„± ì‹¤íŒ¨: {e}")
        return
    
    # 5. ì»¤ìŠ¤í…€ ë°ì´í„°ë¡œë” ìƒì„± (ë¹„ë””ì˜¤ íŒŒì¼ ì§ì ‘ ì²˜ë¦¬)
    print(f"\nğŸ“Š ì»¤ìŠ¤í…€ ë¹„ë””ì˜¤ ë°ì´í„°ë¡œë” ìƒì„±...")
    try:
        # Avenue ë°ì´í„° ëª¨ë“ˆ ì‚¬ìš© (AI-VAD í‘œì¤€)
        datamodule = Avenue(
            root=dataset_root,
            clip_length_in_frames=2,  # AI-VAD í‘œì¤€
            frames_between_clips=1,
            target_frame=VideoTargetFrame.LAST,
            train_batch_size=1,  # ì‘ì€ ë°°ì¹˜ í¬ê¸°
            eval_batch_size=1,
            num_workers=0,
        )
        
        print("âœ… ì»¤ìŠ¤í…€ ë°ì´í„°ë¡œë” ìƒì„± ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ ì»¤ìŠ¤í…€ ë°ì´í„°ë¡œë” ìƒì„± ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ Avenue ë°ì´í„°ì…‹ êµ¬ì¡°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return
    
    # 6. AI-VAD í•™ìŠµ (ì˜¬ë°”ë¥¸ ë°©ë²•)
    print(f"\nğŸ¯ AI-VAD í•™ìŠµ ì‹œì‘...")
    print("ğŸ’¡ í•™ìŠµ ê³¼ì •:")
    print("   1. Feature Extraction: Flow, Region, Pose, Deep features")
    print("   2. Density Update: ì •ìƒ íŠ¹ì„±ë“¤ì„ density estimatorì— ëˆ„ì ")
    print("   3. Density Fit: ëª¨ë“  íŠ¹ì„±ìœ¼ë¡œ ë¶„í¬ ëª¨ë¸ í•™ìŠµ")
    print("   4. No Backpropagation: ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ ì—†ìŒ!")
    
    try:
        # AI-VADì˜ ì˜¬ë°”ë¥¸ í•™ìŠµ ë°©ë²•
        engine.fit(model=model, datamodule=datamodule)
        
        print("âœ… AI-VAD í•™ìŠµ ì™„ë£Œ!")
        
        # Density estimator ìƒíƒœ í™•ì¸
        if hasattr(model.model, 'density_estimator'):
            print(f"ğŸ“Š Density Estimator ìƒíƒœ:")
            print(f"   - ì´ ê°ì§€ ìˆ˜: {model.total_detections}")
            
            # Density estimator fit í˜¸ì¶œ
            if model.total_detections > 0:
                model.fit()  # density estimator í•™ìŠµ
                print("âœ… Density Estimator í•™ìŠµ ì™„ë£Œ")
            else:
                print("âš ï¸ ê°ì§€ëœ ì˜ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"âŒ AI-VAD í•™ìŠµ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # 7. ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    checkpoint_path = "aivad_proper_learned.ckpt"
    try:
        # AI-VAD ëª¨ë¸ ìƒíƒœ ì €ì¥
        torch.save({
            'state_dict': model.state_dict(),
            'pytorch-lightning_version': '2.0.0',
            'model_class': 'AiVad',
            'training_type': 'proper_density_estimation',
            'total_detections': model.total_detections,
        }, checkpoint_path)
        
        print(f"ğŸ’¾ í•™ìŠµëœ ëª¨ë¸ ì €ì¥: {checkpoint_path}")
        print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {os.path.getsize(checkpoint_path) / (1024**2):.1f} MB")
        
    except Exception as e:
        print(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    print("\nğŸ‰ AI-VAD ì˜¬ë°”ë¥¸ í•™ìŠµ ì™„ë£Œ!")
    print("ğŸ’¡ í•™ìŠµëœ ë‚´ìš©:")
    print("1. ì •ìƒ ë°ì´í„°ì˜ Feature ë¶„í¬ í•™ìŠµ")
    print("2. Density Estimatorë¡œ ì´ìƒ íƒì§€ ì¤€ë¹„")
    print("3. UIì—ì„œ 'aivad_proper_learned.ckpt' ë¡œë“œí•˜ì—¬ í…ŒìŠ¤íŠ¸")
    print("4. ë¹„ì •ìƒ ë°ì´í„°ëŠ” ë¶„í¬ì—ì„œ ë²—ì–´ë‚˜ ë†’ì€ ì ìˆ˜")

if __name__ == "__main__":
    main()
