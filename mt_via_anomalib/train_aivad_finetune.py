"""
AI-VAD λ¨λΈ νμΈνλ‹ μ¤ν¬λ¦½νΈ
κΈ°μ΅΄μ— ν›λ ¨λ AI-VAD λ¨λΈμ„ μ°λ¦¬ λ°μ΄ν„°λ΅ νμΈνλ‹ν•©λ‹λ‹¤.

μ¥μ :
- λΉ λ¥Έ ν•™μµ μ‹κ°„ (κΈ°μ΅΄ κ°€μ¤‘μΉ ν™μ©)
- μ•μ •μ μΈ ν•™μµ (μ‚¬μ „ ν›λ ¨λ νΉμ§• ν™μ©)
- μ μ€ λ°μ΄ν„°λ΅λ„ ν¨κ³Όμ 

λ‹¨μ :
- κΈ°μ΅΄ λ°μ΄ν„°μ…‹μ νΈν–¥μ— μν–¥λ°›μ„ μ μμ
- λ„λ©”μΈ μ°¨μ΄κ°€ ν¬λ©΄ μ„±λ¥ μ ν•
"""

import os
import torch
import torch.nn as nn
from pathlib import Path
import cv2
import numpy as np
from anomalib.models.video import AiVad
from anomalib.engine import Engine
from anomalib.data.utils.split import ValSplitMode
import logging

# λ΅κΉ… μ„¤μ •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class CustomVideoDataModule:
    """μ»¤μ¤ν…€ λΉ„λ””μ¤ λ°μ΄ν„° λ¨λ“"""
    
    def __init__(self, video_paths, clip_length=2, frames_between_clips=1):
        self.video_paths = video_paths
        self.clip_length = clip_length
        self.frames_between_clips = frames_between_clips
        
    def setup(self):
        """λ°μ΄ν„°μ…‹ μ„¤μ •"""
        print(f"π“ λΉ„λ””μ¤ νμΌ {len(self.video_paths)}κ° λ΅λ“ μ¤‘...")
        
        # λΉ„λ””μ¤λ³„ ν”„λ μ„ μ ν™•μΈ
        self.video_info = {}
        for video_path in self.video_paths:
            cap = cv2.VideoCapture(video_path)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            self.video_info[video_path] = frame_count
            cap.release()
            print(f"  - {Path(video_path).name}: {frame_count} frames")
        
        print(f"β… μ΄ {sum(self.video_info.values())} ν”„λ μ„ λ΅λ“ μ™„λ£")
        
    def train_dataloader(self):
        """ν›λ ¨ λ°μ΄ν„° λ΅λ”"""
        # μ‹¤μ  κµ¬ν„μ—μ„λ” λΉ„λ””μ¤ ν΄λ¦½μ„ μƒμ„±ν•λ” λ΅μ§ ν•„μ”
        # μ—¬κΈ°μ„λ” λ”λ―Έ λ°μ΄ν„° λ°ν™
        return self._create_dummy_dataloader()
    
    def val_dataloader(self):
        """κ²€μ¦ λ°μ΄ν„° λ΅λ”"""
        return self._create_dummy_dataloader()
    
    def _create_dummy_dataloader(self):
        """λ”λ―Έ λ°μ΄ν„° λ΅λ” μƒμ„±"""
        # μ‹¤μ  λΉ„λ””μ¤ λ°μ΄ν„° λ΅λ” κµ¬ν„ ν•„μ”
        return None

def load_pretrained_model(checkpoint_path="aivad_proper_checkpoint.ckpt"):
    """μ‚¬μ „ ν›λ ¨λ λ¨λΈ λ΅λ“"""
    print(f"π”„ μ‚¬μ „ ν›λ ¨λ λ¨λΈ λ΅λ“: {checkpoint_path}")
    
    if not os.path.exists(checkpoint_path):
        print(f"β μ²΄ν¬ν¬μΈνΈ νμΌμ΄ μ—†μµλ‹λ‹¤: {checkpoint_path}")
        return None
    
    try:
        # μ²΄ν¬ν¬μΈνΈ λ΅λ“
        checkpoint = torch.load(checkpoint_path, weights_only=False)
        
        # λ¨λΈ μƒμ„±
        model = AiVad()
        
        # κ°€μ¤‘μΉ λ΅λ“
        if 'state_dict' in checkpoint:
            model.load_state_dict(checkpoint['state_dict'], strict=False)
            print("β… μ‚¬μ „ ν›λ ¨λ κ°€μ¤‘μΉ λ΅λ“ μ™„λ£")
        else:
            print("β οΈ state_dictκ°€ μ—†μµλ‹λ‹¤. λλ¤ μ΄κΈ°ν™”λ΅ μ‹μ‘ν•©λ‹λ‹¤.")
        
        return model
        
    except Exception as e:
        print(f"β λ¨λΈ λ΅λ“ μ‹¤ν¨: {e}")
        return None

def setup_finetune_optimizer(model, learning_rate=1e-5):
    """νμΈνλ‹μ© μµν‹°λ§μ΄μ € μ„¤μ •"""
    print(f"β™οΈ νμΈνλ‹ μµν‹°λ§μ΄μ € μ„¤μ • (LR: {learning_rate})")
    
    # νμΈνλ‹μ„ μ„ν•΄ λ‚®μ€ ν•™μµλ¥  μ‚¬μ©
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=learning_rate,
        weight_decay=0.01
    )
    
    # ν•™μµλ¥  μ¤μΌ€μ¤„λ¬
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=10, eta_min=1e-7
    )
    
    return optimizer, scheduler

def main():
    """λ©”μΈ ν•¨μ"""
    print("π€ AI-VAD λ¨λΈ νμΈνλ‹ μ‹μ‘")
    print("=" * 50)
    
    # GPU μ„¤μ •
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"π–¥οΈ μ‚¬μ© λ””λ°”μ΄μ¤: {device}")
    
    if device == "cuda":
        print(f"GPU: {torch.cuda.get_device_name()}")
        print(f"GPU λ©”λ¨λ¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # λΉ„λ””μ¤ νμΌ κ²½λ΅ μ„¤μ •
    from video_files_list import video_files
    video_paths = video_files
    
    print(f"π“ ν›λ ¨ν•  λΉ„λ””μ¤ νμΌ: {len(video_paths)}κ°")
    for i, path in enumerate(video_paths[:3]):  # μ²μ 3κ°λ§ ν‘μ‹
        print(f"  {i+1}. {Path(path).name}")
    if len(video_paths) > 3:
        print(f"  ... μ™Έ {len(video_paths)-3}κ°")
    
    # λ°μ΄ν„° λ¨λ“ μ„¤μ •
    print("\nπ“ λ°μ΄ν„° λ¨λ“ μ„¤μ •...")
    datamodule = CustomVideoDataModule(
        video_paths=video_paths,
        clip_length=2,
        frames_between_clips=1
    )
    datamodule.setup()
    
    # μ‚¬μ „ ν›λ ¨λ λ¨λΈ λ΅λ“
    print("\nπ¤– μ‚¬μ „ ν›λ ¨λ λ¨λΈ λ΅λ“...")
    model = load_pretrained_model("aivad_proper_checkpoint.ckpt")
    
    if model is None:
        print("β λ¨λΈ λ΅λ“ μ‹¤ν¨. μƒ λ¨λΈλ΅ μ‹μ‘ν•©λ‹λ‹¤.")
        model = AiVad()
    
    # νμΈνλ‹ μµν‹°λ§μ΄μ € μ„¤μ •
    print("\nβ™οΈ νμΈνλ‹ μ„¤μ •...")
    optimizer, scheduler = setup_finetune_optimizer(model, learning_rate=1e-5)
    
    # ν•™μµ μ—”μ§„ μ„¤μ • (νμΈνλ‹μ©)
    print("\nπ”§ ν•™μµ μ—”μ§„ μ„¤μ •...")
    engine = Engine(
        devices=1 if device == "cuda" else "auto",
        accelerator="gpu" if device == "cuda" else "cpu",
        precision="16-mixed" if device == "cuda" else "32",
        max_epochs=5,  # νμΈνλ‹μ€ μ μ€ μ—ν¬ν¬
        gradient_clip_val=1.0,
        accumulate_grad_batches=2,  # κ·Έλλ””μ–ΈνΈ λ„μ 
        log_every_n_steps=10,
        val_check_interval=0.5,
        enable_progress_bar=True,
        enable_model_summary=True,
        # νμΈνλ‹μ„ μ„ν• μ ν•
        limit_train_batches=20,  # λ°°μΉ μ μ ν•
        limit_val_batches=10,
    )
    
    # ν•™μµ μ‹μ‘
    print("\nπ― νμΈνλ‹ μ‹μ‘!")
    try:
        # μ‹¤μ  λ°μ΄ν„° λ΅λ”κ°€ κµ¬ν„λλ©΄ μ΄ λ¶€λ¶„ ν™μ„±ν™”
        # engine.fit(model=model, datamodule=datamodule)
        
        print("β οΈ μ‹¤μ  λ°μ΄ν„° λ΅λ” κµ¬ν„ ν•„μ”")
        print("ν„μ¬λ” λ”λ―Έ λ¨λ“λ΅ μ‹¤ν–‰λ©λ‹λ‹¤.")
        
        # λ”λ―Έ ν•™μµ (μ‹¤μ  κµ¬ν„μ—μ„λ” μ κ±°)
        print("π”§ λ”λ―Έ ν•™μµ μ‹¤ν–‰...")
        model.train()
        
        # λ”λ―Έ μ…λ ¥ μƒμ„±
        dummy_input = torch.randn(1, 2, 3, 224, 224).to(device)
        
        # Forward pass
        with torch.no_grad():
            output = model(dummy_input)
            print(f"β… λ¨λΈ forward pass μ„±κ³µ")
            print(f"μ¶λ ¥ νƒ€μ…: {type(output)}")
        
        # μ²΄ν¬ν¬μΈνΈ μ €μ¥
        checkpoint_path = "aivad_finetuned.ckpt"
        torch.save({
            'state_dict': model.state_dict(),
            'pytorch-lightning_version': '2.0.0',
            'model_class': 'AiVad',
            'training_type': 'finetuned'
        }, checkpoint_path)
        
        print(f"π’Ύ νμΈνλ‹λ λ¨λΈ μ €μ¥: {checkpoint_path}")
        print(f"π“ νμΌ ν¬κΈ°: {os.path.getsize(checkpoint_path) / (1024**2):.1f} MB")
        
        print("\nπ‰ νμΈνλ‹ μ™„λ£!")
        print("π’΅ λ‹¤μ λ‹¨κ³„:")
        print("1. UIμ—μ„ 'aivad_finetuned.ckpt' λ΅λ“")
        print("2. μ‹¤μ  μ„±λ¥ ν…μ¤νΈ")
        print("3. ν•„μ”μ‹ μ¶”κ°€ νμΈνλ‹")
        
    except Exception as e:
        print(f"β νμΈνλ‹ μ¤‘ μ¤λ¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
