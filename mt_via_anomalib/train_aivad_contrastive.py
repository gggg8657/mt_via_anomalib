"""
ëŒ€ì¡° í•™ìŠµì„ í†µí•œ AI-VAD íŒŒì¸íŠœë‹
ì •ìƒ ë°ì´í„° + ìƒì„±ëœ ë¹„ì •ìƒ ë°ì´í„°ë¡œ ëŒ€ì¡° í•™ìŠµ
"""

import os
import json
import torch
import cv2
import numpy as np
from pathlib import Path
from anomalib.models.video import AiVad
import shutil
from torch.utils.data import Dataset, DataLoader
import random

class ContrastiveVideoDataset(Dataset):
    """ì •ìƒ + ë¹„ì •ìƒ ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ ëŒ€ì¡° í•™ìŠµ ë°ì´í„°ì…‹"""
    
    def __init__(self, image_folder, sequence_length=2, transform=None):
        self.image_folder = Path(image_folder)
        self.sequence_length = sequence_length
        self.transform = transform
        
        # ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜ì§‘
        self.image_files = sorted([f for f in self.image_folder.glob("*.jpg")])
        print(f"ğŸ“¸ ì´ {len(self.image_files)}ê°œ ì´ë¯¸ì§€ ë°œê²¬")
        
        # ì‹œí€€ìŠ¤ ìƒì„± (ì—°ì†ëœ í”„ë ˆì„ë“¤)
        self.sequences = []
        for i in range(len(self.image_files) - sequence_length + 1):
            sequence = self.image_files[i:i + sequence_length]
            self.sequences.append(sequence)
        
        print(f"ğŸ¬ {len(self.sequences)}ê°œ ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ ìƒì„±")
        
        # ì •ìƒ/ë¹„ì •ìƒ ë¼ë²¨ ìƒì„± (50:50 ë¹„ìœ¨)
        self.labels = []
        self.data_pairs = []
        
        for i, sequence in enumerate(self.sequences):
            # ì •ìƒ ë°ì´í„° (ì›ë³¸)
            normal_frames = self._load_sequence(sequence)
            self.data_pairs.append((normal_frames, 0))  # 0 = ì •ìƒ
            
            # ë¹„ì •ìƒ ë°ì´í„° ìƒì„± (ë…¸ì´ì¦ˆ, íšŒì „, ë°ê¸° ë³€í™” ë“±)
            if len(self.image_files) > sequence_length:
                # ë‹¤ë¥¸ í”„ë ˆì„ë“¤ë¡œ ëœë¤ ì‹œí€€ìŠ¤ ìƒì„± (ë¹„ì •ìƒ)
                anomaly_sequence = random.sample(self.image_files, sequence_length)
                anomaly_frames = self._load_sequence(anomaly_sequence)
                self.data_pairs.append((anomaly_frames, 1))  # 1 = ë¹„ì •ìƒ
        
        print(f"ğŸ¯ ì´ {len(self.data_pairs)}ê°œ ë°ì´í„° í˜ì–´ ìƒì„±")
        print(f"   ğŸ“Š ì •ìƒ: {sum(1 for _, label in self.data_pairs if label == 0)}ê°œ")
        print(f"   ğŸ“Š ë¹„ì •ìƒ: {sum(1 for _, label in self.data_pairs if label == 1)}ê°œ")
    
    def _load_sequence(self, sequence_paths):
        """ì‹œí€€ìŠ¤ ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        frames = []
        
        for path in sequence_paths:
            frame = cv2.imread(str(path))
            if frame is None:
                # ë¹ˆ í”„ë ˆì„ ìƒì„±
                frame = np.zeros((224, 224, 3), dtype=np.uint8)
            else:
                # 224x224ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                frame = cv2.resize(frame, (224, 224))
            
            # BGR to RGB
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # ì •ê·œí™” [0, 1]
            frame = frame.astype(np.float32) / 255.0
            
            # CHW í˜•íƒœë¡œ ë³€í™˜
            frame = np.transpose(frame, (2, 0, 1))
            frames.append(frame)
        
        return np.array(frames)
    
    def __len__(self):
        return len(self.data_pairs)
    
    def __getitem__(self, idx):
        frames, label = self.data_pairs[idx]
        
        # í…ì„œë¡œ ë³€í™˜ [sequence_length, 3, 224, 224]
        video_tensor = torch.from_numpy(frames)
        
        # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ [1, sequence_length, 3, 224, 224]
        video_tensor = video_tensor.unsqueeze(0)
        
        return {
            'image': video_tensor,
            'label': torch.tensor(label, dtype=torch.float32),
            'image_path': str(self.image_files[0]) if len(self.image_files) > 0 else "dummy"
        }

def create_contrastive_dataset_from_json(json_path="image_segments.json", target_dir="contrastive_dataset"):
    """JSONì—ì„œ ì •ìƒ í”„ë ˆì„ë“¤ì„ ëŒ€ì¡° í•™ìŠµìš©ìœ¼ë¡œ ë³€í™˜"""
    print(f"ğŸ“ ëŒ€ì¡° í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„±: {json_path}")
    
    # í´ë” ìƒì„±
    normal_dir = Path(target_dir) / "train" / "good"
    normal_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"  ğŸ“‚ ì •ìƒ ì´ë¯¸ì§€ í´ë”: {normal_dir}")
    
    # JSON íŒŒì¼ ë¡œë“œ
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            segments = json.load(f)
        print(f"  ğŸ“Š JSON ë¡œë“œ ì™„ë£Œ: {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
    except Exception as e:
        print(f"âŒ JSON ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None
    
    # ì •ìƒ í”„ë ˆì„ë“¤ ì¶”ì¶œ
    copied_count = 0
    normal_count = 0
    
    for i, segment in enumerate(segments):
        if segment.get('category') == 'normal' and 'images' in segment:
            normal_count += 1
            images = segment['images']
            
            # ê° ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ì—°ì†ëœ í”„ë ˆì„ë“¤ ì‚¬ìš©
            for j in range(min(3, len(images) - 1)):  # ìµœëŒ€ 3ê°œ ì‹œí€€ìŠ¤
                img1_path = images[j]
                img2_path = images[j + 1]
                
                if os.path.exists(img1_path) and os.path.exists(img2_path):
                    # íŒŒì¼ëª… ìƒì„±
                    name1 = f"seq_{normal_count:03d}_{j:02d}_frame1_{Path(img1_path).name}"
                    name2 = f"seq_{normal_count:03d}_{j:02d}_frame2_{Path(img2_path).name}"
                    
                    target1 = normal_dir / name1
                    target2 = normal_dir / name2
                    
                    try:
                        # íŒŒì¼ ë³µì‚¬
                        shutil.copy2(img1_path, target1)
                        shutil.copy2(img2_path, target2)
                        copied_count += 2
                        
                        if copied_count <= 20:  # ì²˜ìŒ 20ê°œë§Œ í‘œì‹œ
                            print(f"    ğŸ¬ {name1}")
                            print(f"    ğŸ¬ {name2}")
                            
                    except Exception as e:
                        print(f"    âš ï¸ {img1_path} ë³µì‚¬ ì‹¤íŒ¨: {e}")
    
    print(f"  âœ… ì •ìƒ ì„¸ê·¸ë¨¼íŠ¸: {normal_count}ê°œ")
    print(f"  âœ… ë³µì‚¬ëœ ì´ë¯¸ì§€: {copied_count}ê°œ")
    
    if copied_count == 0:
        print("âŒ ë³µì‚¬ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return None
    
    return str(Path(target_dir).absolute())

def contrastive_loss(pred_scores, labels, margin=0.5):
    """ëŒ€ì¡° í•™ìŠµ ì†ì‹¤ í•¨ìˆ˜"""
    # ì •ìƒ ë°ì´í„°ëŠ” ë‚®ì€ ì ìˆ˜, ë¹„ì •ìƒ ë°ì´í„°ëŠ” ë†’ì€ ì ìˆ˜ ëª©í‘œ
    target_scores = torch.where(labels == 0, torch.tensor(0.1), torch.tensor(0.9))
    
    # MSE ì†ì‹¤
    mse_loss = torch.nn.functional.mse_loss(pred_scores.squeeze(), target_scores)
    
    # ëŒ€ì¡° ì†ì‹¤ (ì •ìƒê³¼ ë¹„ì •ìƒ ê°„ ê±°ë¦¬)
    normal_scores = pred_scores[labels == 0]
    anomaly_scores = pred_scores[labels == 1]
    
    if len(normal_scores) > 0 and len(anomaly_scores) > 0:
        contrastive_loss = torch.nn.functional.relu(margin - (anomaly_scores.mean() - normal_scores.mean()))
        return mse_loss + contrastive_loss
    else:
        return mse_loss

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ëŒ€ì¡° í•™ìŠµìœ¼ë¡œ AI-VAD íŒŒì¸íŠœë‹")
    print("=" * 50)
    
    # GPU ì„¤ì •
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ–¥ï¸ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    if device == "cuda":
        print(f"GPU: {torch.cuda.get_device_name()}")
    
    # 1. ëŒ€ì¡° í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„±
    dataset_root = create_contrastive_dataset_from_json()
    if dataset_root is None:
        print("âŒ ëŒ€ì¡° í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨")
        return
    
    # 2. ëŒ€ì¡° í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„±
    print(f"\nğŸ“Š ëŒ€ì¡° í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„±...")
    try:
        normal_dir = Path(dataset_root) / "train" / "good"
        contrastive_dataset = ContrastiveVideoDataset(normal_dir, sequence_length=2)
        
        # DataLoader ìƒì„±
        dataloader = DataLoader(
            contrastive_dataset,
            batch_size=4,  # ë” í° ë°°ì¹˜ í¬ê¸°
            shuffle=True,
            num_workers=0,
            drop_last=True
        )
        
        print(f"âœ… ëŒ€ì¡° í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ")
        print(f"   ğŸ“Š ë°°ì¹˜ í¬ê¸°: {dataloader.batch_size}")
        print(f"   ğŸ“Š ì´ ë°°ì¹˜ ìˆ˜: {len(dataloader)}")
        
    except Exception as e:
        print(f"âŒ ëŒ€ì¡° í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨: {e}")
        return
    
    # 3. AI-VAD ëª¨ë¸ ìƒì„±
    print(f"\nğŸ¤– AI-VAD ëª¨ë¸ ìƒì„±...")
    try:
        model = AiVad()
        print("âœ… AI-VAD ëª¨ë¸ ìƒì„± ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ AI-VAD ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return
    
    # 4. ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
    checkpoint_path = "aivad_proper_checkpoint.ckpt"
    if os.path.exists(checkpoint_path):
        print(f"\nğŸ”„ ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ: {checkpoint_path}")
        try:
            checkpoint = torch.load(checkpoint_path, weights_only=False)
            if 'state_dict' in checkpoint:
                model.load_state_dict(checkpoint['state_dict'], strict=False)
                print("âœ… ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ")
            else:
                print("âš ï¸ state_dictê°€ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # 5. ëŒ€ì¡° í•™ìŠµ í›ˆë ¨
    print(f"\nğŸ¯ ëŒ€ì¡° í•™ìŠµ ì‹œì‘...")
    try:
        model.to(device)
        
        # ëª¨ë¸ì„ train ëª¨ë“œë¡œ ì„¤ì •
        model.train()
        model.model.train()
        
        # ëª¨ë“  íŒŒë¼ë¯¸í„°ì˜ gradient í™œì„±í™”
        for param in model.parameters():
            param.requires_grad = True
        
        # ì˜µí‹°ë§ˆì´ì € ì„¤ì •
        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
        
        # í›ˆë ¨ ë£¨í”„
        for epoch in range(5):  # 5 ì—í¬í¬
            print(f"\nğŸ“ˆ Epoch {epoch + 1}/5")
            
            total_loss = 0
            batch_count = 0
            normal_count = 0
            anomaly_count = 0
            
            for batch_idx, batch in enumerate(dataloader):
                try:
                    # ë°ì´í„°ë¥¼ GPUë¡œ ì´ë™
                    video_tensor = batch['image'].to(device)  # [batch_size, 1, 2, 3, 224, 224]
                    labels = batch['label'].to(device)  # [batch_size]
                    
                    # ë°°ì¹˜ ì°¨ì› ì¡°ì • [batch_size, 2, 3, 224, 224]
                    video_tensor = video_tensor.squeeze(1)
                    
                    # ëª¨ë¸ ìˆœì „íŒŒ
                    optimizer.zero_grad()
                    
                    # AI-VAD ëª¨ë¸ í˜¸ì¶œ
                    output = model.model(video_tensor)
                    
                    # ì¶œë ¥ì—ì„œ pred_score ì¶”ì¶œ
                    if hasattr(output, 'pred_score'):
                        pred_scores = output.pred_score
                    elif isinstance(output, dict) and 'pred_score' in output:
                        pred_scores = output['pred_score']
                    elif torch.is_tensor(output):
                        pred_scores = output
                    else:
                        print(f"    âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì¶œë ¥ í˜•íƒœ")
                        continue
                    
                    # ëŒ€ì¡° í•™ìŠµ ì†ì‹¤ ê³„ì‚°
                    loss = contrastive_loss(pred_scores, labels)
                    
                    # ì—­ì „íŒŒ
                    loss.backward()
                    optimizer.step()
                    
                    total_loss += loss.item()
                    batch_count += 1
                    
                    # ë¼ë²¨ í†µê³„
                    normal_count += (labels == 0).sum().item()
                    anomaly_count += (labels == 1).sum().item()
                    
                    # ì§„í–‰ë¥  í‘œì‹œ (5ë°°ì¹˜ë§ˆë‹¤)
                    if batch_idx % 5 == 0:
                        normal_score = pred_scores[labels == 0].mean().item() if (labels == 0).sum() > 0 else 0
                        anomaly_score = pred_scores[labels == 1].mean().item() if (labels == 1).sum() > 0 else 0
                        print(f"  Batch {batch_idx + 1}: Loss = {loss.item():.4f}, Normal = {normal_score:.3f}, Anomaly = {anomaly_score:.3f}")
                    
                except Exception as e:
                    print(f"  âš ï¸ Batch {batch_idx + 1} ì‹¤íŒ¨: {e}")
                    continue
            
            if batch_count > 0:
                avg_loss = total_loss / batch_count
                print(f"  ğŸ“Š í‰ê·  ì†ì‹¤: {avg_loss:.4f} (ì´ {batch_count}ê°œ ë°°ì¹˜)")
                print(f"  ğŸ“Š ì •ìƒ ë°ì´í„°: {normal_count}ê°œ, ë¹„ì •ìƒ ë°ì´í„°: {anomaly_count}ê°œ")
            else:
                print(f"  âš ï¸ ì„±ê³µí•œ ë°°ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        print("âœ… ëŒ€ì¡° í•™ìŠµ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ëŒ€ì¡° í•™ìŠµ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # 6. ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    checkpoint_path = "aivad_contrastive_finetuned.ckpt"
    try:
        torch.save({
            'state_dict': model.state_dict(),
            'pytorch-lightning_version': '2.0.0',
            'model_class': 'AiVad',
            'training_type': 'contrastive_finetuned'
        }, checkpoint_path)
        
        print(f"ğŸ’¾ ëŒ€ì¡° í•™ìŠµëœ ëª¨ë¸ ì €ì¥: {checkpoint_path}")
        print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {os.path.getsize(checkpoint_path) / (1024**2):.1f} MB")
        
    except Exception as e:
        print(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    print("\nğŸ‰ ëŒ€ì¡° í•™ìŠµìœ¼ë¡œ AI-VAD íŒŒì¸íŠœë‹ ì™„ë£Œ!")
    print("ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print("1. UIì—ì„œ 'aivad_contrastive_finetuned.ckpt' ë¡œë“œ")
    print("2. ì‹¤ì œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("3. ì •ìƒ/ë¹„ì •ìƒ êµ¬ë¶„ ì„±ëŠ¥ í™•ì¸")

if __name__ == "__main__":
    main()
