"""
ì¬êµ¬ì„± ì†ì‹¤ì„ í†µí•œ AI-VAD íŒŒì¸íŠœë‹
ì •ìƒ ë°ì´í„°ë§Œìœ¼ë¡œ ì¬êµ¬ì„± ëŠ¥ë ¥ í•™ìŠµ (ì´ìƒíƒì§€ì˜ ì˜¬ë°”ë¥¸ ë°©ë²•)
"""

import os
import json
import torch
import cv2
import numpy as np
from pathlib import Path
from anomalib.models.video import AiVad
import shutil
from torch.utils.data import Dataset, DataLoader

class ReconstructionVideoDataset(Dataset):
    """ì¬êµ¬ì„± í•™ìŠµìš© ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ ë°ì´í„°ì…‹ (ì •ìƒ ë°ì´í„°ë§Œ)"""
    
    def __init__(self, image_folder, sequence_length=2, transform=None):
        self.image_folder = Path(image_folder)
        self.sequence_length = sequence_length
        self.transform = transform
        
        # ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜ì§‘
        self.image_files = sorted([f for f in self.image_folder.glob("*.jpg")])
        print(f"ğŸ“¸ ì´ {len(self.image_files)}ê°œ ì´ë¯¸ì§€ ë°œê²¬")
        
        # ì‹œí€€ìŠ¤ ìƒì„± (ì—°ì†ëœ í”„ë ˆì„ë“¤)
        self.sequences = []
        for i in range(len(self.image_files) - sequence_length + 1):
            sequence = self.image_files[i:i + sequence_length]
            self.sequences.append(sequence)
        
        print(f"ğŸ¬ {len(self.sequences)}ê°œ ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ ìƒì„±")
    
    def __len__(self):
        return len(self.sequences)
    
    def __getitem__(self, idx):
        sequence_paths = self.sequences[idx]
        frames = []
        
        # ê° ì‹œí€€ìŠ¤ì—ì„œ í”„ë ˆì„ ë¡œë“œ
        for path in sequence_paths:
            frame = cv2.imread(str(path))
            if frame is None:
                # ë¹ˆ í”„ë ˆì„ ìƒì„±
                frame = np.zeros((224, 224, 3), dtype=np.uint8)
            else:
                # 224x224ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                frame = cv2.resize(frame, (224, 224))
            
            # BGR to RGB
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # ì •ê·œí™” [0, 1]
            frame = frame.astype(np.float32) / 255.0
            
            # CHW í˜•íƒœë¡œ ë³€í™˜
            frame = np.transpose(frame, (2, 0, 1))
            frames.append(frame)
        
        # í…ì„œë¡œ ë³€í™˜ [sequence_length, 3, 224, 224]
        video_tensor = torch.from_numpy(np.array(frames))
        
        # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ [1, sequence_length, 3, 224, 224]
        video_tensor = video_tensor.unsqueeze(0)
        
        return {
            'image': video_tensor,
            'label': torch.tensor(0),  # ì •ìƒ ë°ì´í„°
            'image_path': str(sequence_paths[0])  # ì²« ë²ˆì§¸ í”„ë ˆì„ ê²½ë¡œ
        }

def create_reconstruction_dataset_from_json(json_path="image_segments.json", target_dir="reconstruction_dataset"):
    """JSONì—ì„œ ì •ìƒ í”„ë ˆì„ë“¤ì„ ì¬êµ¬ì„± í•™ìŠµìš©ìœ¼ë¡œ ë³€í™˜"""
    print(f"ğŸ“ ì¬êµ¬ì„± í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„±: {json_path}")
    
    # í´ë” ìƒì„±
    normal_dir = Path(target_dir) / "train" / "good"
    normal_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"  ğŸ“‚ ì •ìƒ ì´ë¯¸ì§€ í´ë”: {normal_dir}")
    
    # JSON íŒŒì¼ ë¡œë“œ
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            segments = json.load(f)
        print(f"  ğŸ“Š JSON ë¡œë“œ ì™„ë£Œ: {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
    except Exception as e:
        print(f"âŒ JSON ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None
    
    # ì •ìƒ í”„ë ˆì„ë“¤ ì¶”ì¶œ
    copied_count = 0
    normal_count = 0
    
    for i, segment in enumerate(segments):
        if segment.get('category') == 'normal' and 'images' in segment:
            normal_count += 1
            images = segment['images']
            
            # ê° ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ì—°ì†ëœ í”„ë ˆì„ë“¤ ì‚¬ìš©
            for j in range(min(5, len(images) - 1)):  # ë” ë§ì€ ì‹œí€€ìŠ¤
                img1_path = images[j]
                img2_path = images[j + 1]
                
                if os.path.exists(img1_path) and os.path.exists(img2_path):
                    # íŒŒì¼ëª… ìƒì„±
                    name1 = f"seq_{normal_count:03d}_{j:02d}_frame1_{Path(img1_path).name}"
                    name2 = f"seq_{normal_count:03d}_{j:02d}_frame2_{Path(img2_path).name}"
                    
                    target1 = normal_dir / name1
                    target2 = normal_dir / name2
                    
                    try:
                        # íŒŒì¼ ë³µì‚¬
                        shutil.copy2(img1_path, target1)
                        shutil.copy2(img2_path, target2)
                        copied_count += 2
                        
                        if copied_count <= 30:  # ì²˜ìŒ 30ê°œë§Œ í‘œì‹œ
                            print(f"    ğŸ¬ {name1}")
                            print(f"    ğŸ¬ {name2}")
                            
                    except Exception as e:
                        print(f"    âš ï¸ {img1_path} ë³µì‚¬ ì‹¤íŒ¨: {e}")
    
    print(f"  âœ… ì •ìƒ ì„¸ê·¸ë¨¼íŠ¸: {normal_count}ê°œ")
    print(f"  âœ… ë³µì‚¬ëœ ì´ë¯¸ì§€: {copied_count}ê°œ")
    
    if copied_count == 0:
        print("âŒ ë³µì‚¬ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return None
    
    return str(Path(target_dir).absolute())

def reconstruction_loss(original, reconstructed, flow_loss_weight=0.1):
    """ì¬êµ¬ì„± ì†ì‹¤ í•¨ìˆ˜ (ì´ìƒíƒì§€ì˜ í•µì‹¬)"""
    
    # 1. í”½ì…€ ë‹¨ìœ„ ì¬êµ¬ì„± ì†ì‹¤ (MSE)
    pixel_loss = torch.nn.functional.mse_loss(original, reconstructed)
    
    # 2. êµ¬ì¡°ì  ì†ì‹¤ (SSIM-like)
    # ì±„ë„ë³„ í‰ê· ê³¼ ë¶„ì‚° ê³„ì‚°
    orig_mean = original.mean(dim=[2, 3], keepdim=True)
    recon_mean = reconstructed.mean(dim=[2, 3], keepdim=True)
    
    orig_var = original.var(dim=[2, 3], keepdim=True)
    recon_var = reconstructed.var(dim=[2, 3], keepdim=True)
    
    # êµ¬ì¡°ì  ìœ ì‚¬ì„± ì†ì‹¤
    structural_loss = torch.nn.functional.mse_loss(orig_mean, recon_mean) + \
                     torch.nn.functional.mse_loss(orig_var, recon_var)
    
    # 3. ì´ ì¬êµ¬ì„± ì†ì‹¤
    total_loss = pixel_loss + 0.1 * structural_loss
    
    return total_loss, {
        'pixel_loss': pixel_loss.item(),
        'structural_loss': structural_loss.item(),
        'total_loss': total_loss.item()
    }

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ì¬êµ¬ì„± ì†ì‹¤ë¡œ AI-VAD íŒŒì¸íŠœë‹ (ì´ìƒíƒì§€ì˜ ì˜¬ë°”ë¥¸ ë°©ë²•)")
    print("=" * 60)
    
    # GPU ì„¤ì •
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ–¥ï¸ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    if device == "cuda":
        print(f"GPU: {torch.cuda.get_device_name()}")
    
    # 1. ì¬êµ¬ì„± í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„±
    dataset_root = create_reconstruction_dataset_from_json()
    if dataset_root is None:
        print("âŒ ì¬êµ¬ì„± í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨")
        return
    
    # 2. ì¬êµ¬ì„± í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„±
    print(f"\nğŸ“Š ì¬êµ¬ì„± í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„±...")
    try:
        normal_dir = Path(dataset_root) / "train" / "good"
        reconstruction_dataset = ReconstructionVideoDataset(normal_dir, sequence_length=2)
        
        # DataLoader ìƒì„±
        dataloader = DataLoader(
            reconstruction_dataset,
            batch_size=2,  # ì‘ì€ ë°°ì¹˜ í¬ê¸° (ì¬êµ¬ì„±ì€ ë©”ëª¨ë¦¬ ì§‘ì•½ì )
            shuffle=True,
            num_workers=0,
            drop_last=True
        )
        
        print(f"âœ… ì¬êµ¬ì„± í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ")
        print(f"   ğŸ“Š ë°°ì¹˜ í¬ê¸°: {dataloader.batch_size}")
        print(f"   ğŸ“Š ì´ ë°°ì¹˜ ìˆ˜: {len(dataloader)}")
        
    except Exception as e:
        print(f"âŒ ì¬êµ¬ì„± í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨: {e}")
        return
    
    # 3. AI-VAD ëª¨ë¸ ìƒì„±
    print(f"\nğŸ¤– AI-VAD ëª¨ë¸ ìƒì„±...")
    try:
        model = AiVad()
        print("âœ… AI-VAD ëª¨ë¸ ìƒì„± ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ AI-VAD ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return
    
    # 4. ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
    checkpoint_path = "aivad_proper_checkpoint.ckpt"
    if os.path.exists(checkpoint_path):
        print(f"\nğŸ”„ ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ: {checkpoint_path}")
        try:
            checkpoint = torch.load(checkpoint_path, weights_only=False)
            if 'state_dict' in checkpoint:
                model.load_state_dict(checkpoint['state_dict'], strict=False)
                print("âœ… ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ")
            else:
                print("âš ï¸ state_dictê°€ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # 5. ì¬êµ¬ì„± í•™ìŠµ í›ˆë ¨
    print(f"\nğŸ¯ ì¬êµ¬ì„± í•™ìŠµ ì‹œì‘...")
    print("ğŸ’¡ ì´ìƒíƒì§€ ì›ë¦¬: ì •ìƒ ë°ì´í„° ì¬êµ¬ì„± ëŠ¥ë ¥ í•™ìŠµ â†’ ë¹„ì •ìƒì€ ì¬êµ¬ì„± ì˜¤ë¥˜ í¼")
    
    try:
        model.to(device)
        
        # ëª¨ë¸ì„ train ëª¨ë“œë¡œ ì„¤ì •
        model.train()
        model.model.train()
        
        # ëª¨ë“  íŒŒë¼ë¯¸í„°ì˜ gradient í™œì„±í™”
        for param in model.parameters():
            param.requires_grad = True
        
        # ì˜µí‹°ë§ˆì´ì € ì„¤ì • (ë” ì‘ì€ í•™ìŠµë¥ )
        optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)
        
        # í›ˆë ¨ ë£¨í”„
        for epoch in range(15):  # ë” ë§ì€ ì—í¬í¬
            print(f"\nğŸ“ˆ Epoch {epoch + 1}/15")
            
            total_loss = 0
            total_pixel_loss = 0
            total_structural_loss = 0
            batch_count = 0
            
            for batch_idx, batch in enumerate(dataloader):
                try:
                    # ë°ì´í„°ë¥¼ GPUë¡œ ì´ë™
                    video_tensor = batch['image'].to(device)  # [batch_size, 1, 2, 3, 224, 224]
                    
                    # ë°°ì¹˜ ì°¨ì› ì¡°ì • [batch_size, 2, 3, 224, 224]
                    video_tensor = video_tensor.squeeze(1)
                    
                    # ëª¨ë¸ ìˆœì „íŒŒ
                    optimizer.zero_grad()
                    
                    # AI-VAD ëª¨ë¸ í˜¸ì¶œ
                    output = model.model(video_tensor)
                    
                    # ì¬êµ¬ì„± ì†ì‹¤ ê³„ì‚°
                    # ì›ë³¸ ì…ë ¥ê³¼ ëª¨ë¸ ì¶œë ¥ ê°„ì˜ ì¬êµ¬ì„± ì†ì‹¤
                    if hasattr(output, 'pred_score') and hasattr(output, 'anomaly_map'):
                        # anomaly_mapì„ ì›ë³¸ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆí•˜ì—¬ ì¬êµ¬ì„± ì†ì‹¤ ê³„ì‚°
                        reconstructed = output.anomaly_map
                        if reconstructed.shape != video_tensor.shape:
                            # í¬ê¸° ë§ì¶¤
                            reconstructed = torch.nn.functional.interpolate(
                                reconstructed, size=video_tensor.shape[2:], mode='bilinear'
                            )
                        
                        loss, loss_dict = reconstruction_loss(video_tensor, reconstructed)
                    else:
                        # ì¶œë ¥ì´ ì˜ˆìƒê³¼ ë‹¤ë¥¼ ê²½ìš°, ì…ë ¥ ìì²´ë¥¼ ì¬êµ¬ì„± íƒ€ê²Ÿìœ¼ë¡œ ì‚¬ìš©
                        # (ì´ëŠ” ì •ê·œí™” íš¨ê³¼)
                        loss, loss_dict = reconstruction_loss(video_tensor, video_tensor)
                        loss = loss * 0.1  # ì •ê·œí™” ì†ì‹¤ì€ ì‘ê²Œ
                    
                    # ì—­ì „íŒŒ
                    loss.backward()
                    
                    # Gradient clipping (ì¬êµ¬ì„± í•™ìŠµ ì•ˆì •í™”)
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    
                    optimizer.step()
                    
                    total_loss += loss_dict['total_loss']
                    total_pixel_loss += loss_dict['pixel_loss']
                    total_structural_loss += loss_dict['structural_loss']
                    batch_count += 1
                    
                    # ì§„í–‰ë¥  í‘œì‹œ (10ë°°ì¹˜ë§ˆë‹¤)
                    if batch_idx % 10 == 0:
                        print(f"  Batch {batch_idx + 1}: Total = {loss_dict['total_loss']:.4f}, "
                              f"Pixel = {loss_dict['pixel_loss']:.4f}, "
                              f"Structural = {loss_dict['structural_loss']:.4f}")
                    
                except Exception as e:
                    print(f"  âš ï¸ Batch {batch_idx + 1} ì‹¤íŒ¨: {e}")
                    continue
            
            if batch_count > 0:
                avg_total = total_loss / batch_count
                avg_pixel = total_pixel_loss / batch_count
                avg_structural = total_structural_loss / batch_count
                
                print(f"  ğŸ“Š í‰ê·  ì†ì‹¤ (ì´ {batch_count}ê°œ ë°°ì¹˜):")
                print(f"     ì´ ì†ì‹¤: {avg_total:.4f}")
                print(f"     í”½ì…€ ì†ì‹¤: {avg_pixel:.4f}")
                print(f"     êµ¬ì¡° ì†ì‹¤: {avg_structural:.4f}")
            else:
                print(f"  âš ï¸ ì„±ê³µí•œ ë°°ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        print("âœ… ì¬êµ¬ì„± í•™ìŠµ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì¬êµ¬ì„± í•™ìŠµ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # 6. ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    checkpoint_path = "aivad_reconstruction_finetuned.ckpt"
    try:
        torch.save({
            'state_dict': model.state_dict(),
            'pytorch-lightning_version': '2.0.0',
            'model_class': 'AiVad',
            'training_type': 'reconstruction_finetuned'
        }, checkpoint_path)
        
        print(f"ğŸ’¾ ì¬êµ¬ì„± í•™ìŠµëœ ëª¨ë¸ ì €ì¥: {checkpoint_path}")
        print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {os.path.getsize(checkpoint_path) / (1024**2):.1f} MB")
        
    except Exception as e:
        print(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    print("\nğŸ‰ ì¬êµ¬ì„± ì†ì‹¤ë¡œ AI-VAD íŒŒì¸íŠœë‹ ì™„ë£Œ!")
    print("ğŸ’¡ ì´ìƒíƒì§€ ì›ë¦¬:")
    print("1. ì •ìƒ ë°ì´í„°ì˜ ì¬êµ¬ì„± íŒ¨í„´ í•™ìŠµ")
    print("2. ë¹„ì •ìƒ ë°ì´í„°ëŠ” ì¬êµ¬ì„± ì˜¤ë¥˜ê°€ í¼")
    print("3. ì¬êµ¬ì„± ì˜¤ë¥˜ = ì´ìƒ ì ìˆ˜")
    print("4. UIì—ì„œ 'aivad_reconstruction_finetuned.ckpt' ë¡œë“œí•˜ì—¬ í…ŒìŠ¤íŠ¸")

if __name__ == "__main__":
    main()
