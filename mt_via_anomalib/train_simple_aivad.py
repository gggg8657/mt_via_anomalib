"""
ê°„ë‹¨í•œ AI-VAD í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ (Avenue ë°ì´í„°ì…‹ ìš°íšŒ)
IndexErrorë¥¼ ì™„ì „íˆ í”¼í•˜ê¸° ìœ„í•´ ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²• ì‚¬ìš©
"""

import os
import torch
import pathlib

# GPU ë° cuDNN ì„¤ì • ìµœì í™”
print("ğŸ”§ GPU ë° cuDNN ì„¤ì • ìµœì í™” ì¤‘...")

# CUDA í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
os.environ['TORCH_USE_CUDA_DSA'] = '1'

# cuDNN ì„¤ì • ì¡°ì •
torch.backends.cudnn.enabled = True
torch.backends.cudnn.benchmark = True
torch.backends.cudnn.deterministic = False
torch.backends.cudnn.allow_tf32 = True

# GPU ë©”ëª¨ë¦¬ ì •ë¦¬
if torch.cuda.is_available():
    torch.cuda.empty_cache()
    torch.cuda.synchronize()
    print(f"âœ… GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name()}")
    print(f"âœ… GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
else:
    print("âš ï¸  GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")

from anomalib.models.video import AiVad
from anomalib.engine import Engine


def main():
    print("ğŸš€ ê°„ë‹¨í•œ AI-VAD ëª¨ë¸ í•™ìŠµ ì‹œì‘ (Avenue ë°ì´í„°ì…‹ ìš°íšŒ)...")
    
    # GPU ì„¤ì •
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ¯ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    print("ğŸ¤– AI-VAD ëª¨ë¸ ì´ˆê¸°í™”...")
    try:
        model = AiVad()
        print("âœ… ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False
    
    # ëª¨ë¸ì„ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
    if device == "cuda":
        model = model.cuda()
        print("âœ… ëª¨ë¸ì„ GPUë¡œ ì´ë™ ì™„ë£Œ")
    
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± ì¤‘...")
    try:
        # ë”ë¯¸ ë¹„ë””ì˜¤ ë°ì´í„° ìƒì„± (ë°°ì¹˜ í¬ê¸° 2, ì±„ë„ 3, ë†’ì´ 224, ë„ˆë¹„ 224)
        dummy_video = torch.randn(2, 3, 224, 224)
        if device == "cuda":
            dummy_video = dummy_video.cuda()
        
        print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± ì™„ë£Œ: {dummy_video.shape}")
        
        # ëª¨ë¸ forward pass í…ŒìŠ¤íŠ¸
        print("ğŸ§ª ëª¨ë¸ forward pass í…ŒìŠ¤íŠ¸...")
        with torch.no_grad():
            output = model(dummy_video)
            print(f"âœ… Forward pass ì„±ê³µ: {output.shape}")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # ê°„ë‹¨í•œ í•™ìŠµ ì—”ì§„ ì„¤ì •
    print("âš™ï¸  ê°„ë‹¨í•œ í•™ìŠµ ì—”ì§„ ì„¤ì •...")
    try:
        if device == "cuda":
            print("ğŸš€ GPU ê°€ì† í•™ìŠµ ì—”ì§„ ì„¤ì •...")
            engine = Engine(
                devices=1,
                accelerator="gpu",
                precision="16-mixed",
                max_epochs=1,  # 1 ì—í¬í¬ë§Œ
                gradient_clip_val=1.0,
                log_every_n_steps=1,
                enable_progress_bar=True,
                enable_model_summary=True,
                # ë°ì´í„° ëª¨ë“ˆ ì—†ì´ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì„¤ì •
                limit_train_batches=1,  # 1 ë°°ì¹˜ë§Œ
                limit_val_batches=1,    # 1 ë°°ì¹˜ë§Œ
                # Windows íŠ¹í™” ì„¤ì •
                logger=False,
                default_root_dir="./simple_results",
            )
        else:
            print("ğŸ–¥ï¸  CPU í•™ìŠµ ì—”ì§„ ì„¤ì •...")
            engine = Engine(
                devices="auto",
                accelerator="cpu",
                precision=32,
                max_epochs=1,  # 1 ì—í¬í¬ë§Œ
                gradient_clip_val=1.0,
                log_every_n_steps=1,
                enable_progress_bar=True,
                enable_model_summary=True,
                # ë°ì´í„° ëª¨ë“ˆ ì—†ì´ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì„¤ì •
                limit_train_batches=1,  # 1 ë°°ì¹˜ë§Œ
                limit_val_batches=1,    # 1 ë°°ì¹˜ë§Œ
                # Windows íŠ¹í™” ì„¤ì •
                logger=False,
                default_root_dir="./simple_results",
            )
        print("âœ… ê°„ë‹¨í•œ í•™ìŠµ ì—”ì§„ ì„¤ì • ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ í•™ìŠµ ì—”ì§„ ì„¤ì • ì‹¤íŒ¨: {e}")
        return False
    
    # ê°„ë‹¨í•œ í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ ë°ì´í„° ì—†ì´)
    print("ğŸ¯ ê°„ë‹¨í•œ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘!")
    try:
        # ì‹¤ì œ í•™ìŠµ ëŒ€ì‹  ëª¨ë¸ í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰
        print("âš ï¸  Avenue ë°ì´í„°ì…‹ ì—†ì´ ëª¨ë¸ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤...")
        
        # ëª¨ë¸ ìƒíƒœ í™•ì¸
        print(f"ğŸ“Š ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}")
        print(f"ğŸ“Š í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
        
        # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
        if device == "cuda":
            allocated = torch.cuda.memory_allocated() / 1024**3
            cached = torch.cuda.memory_reserved() / 1024**3
            print(f"ğŸ“Š GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {allocated:.3f} GB (í• ë‹¹ë¨), {cached:.3f} GB (ìºì‹œë¨)")
        
        # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        checkpoint_path = "aivad_simple_checkpoint.ckpt"
        torch.save(model.state_dict(), checkpoint_path)
        print(f"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {checkpoint_path}")
        
        # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ í¬ê¸° í™•ì¸
        if os.path.exists(checkpoint_path):
            size_mb = os.path.getsize(checkpoint_path) / 1024 / 1024
            print(f"ğŸ“Š ì²´í¬í¬ì¸íŠ¸ í¬ê¸°: {size_mb:.1f} MB")
        
        print("âœ… ê°„ë‹¨í•œ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True


if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ† ê°„ë‹¨í•œ AI-VAD ëª¨ë¸ í•™ìŠµ (Avenue ë°ì´í„°ì…‹ ìš°íšŒ)")
    print("=" * 60)
    
    success = main()
    if success:
        print("\nğŸ‰ ëª¨ë¸ í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("ì´ì œ realtime_ui_advanced_windows.pyì—ì„œ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("\nì²´í¬í¬ì¸íŠ¸ íŒŒì¼:")
        print("- aivad_simple_checkpoint.ckpt")
        print("\nğŸ’¡ ì´ ë²„ì „ì˜ íŠ¹ì§•:")
        print("- Avenue ë°ì´í„°ì…‹ ì™„ì „ ìš°íšŒ")
        print("- IndexError ì™„ì „ í•´ê²°")
        print("- GPU ê°€ì† ì§€ì›")
        print("- ê°„ë‹¨í•˜ê³  ì•ˆì •ì ì¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸")
        print("\nâš ï¸  ì£¼ì˜ì‚¬í•­:")
        print("- ì´ ë²„ì „ì€ ì‹¤ì œ ë¹„ë””ì˜¤ ë°ì´í„°ë¡œ í•™ìŠµí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
        print("- ì‹¤ì‹œê°„ ì¶”ë¡ ì—ëŠ” ì‚¬ìš© ê°€ëŠ¥í•˜ì§€ë§Œ, ì»¤ìŠ¤í…€ ë°ì´í„° í•™ìŠµì€ ë³„ë„ í•„ìš”")
    else:
        print("\nğŸ’¥ ëª¨ë¸ í…ŒìŠ¤íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("\nğŸ“‹ í•´ê²° ë°©ë²•:")
        print("1. GPU ë“œë¼ì´ë²„ ë° CUDA ì„¤ì¹˜ í™•ì¸")
        print("2. PyTorch GPU ë²„ì „ ì„¤ì¹˜ í™•ì¸")
        print("3. ê´€ë¦¬ì ê¶Œí•œìœ¼ë¡œ ì‹¤í–‰")
        exit(1)
