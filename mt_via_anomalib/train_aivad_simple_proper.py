"""
AI-VADì˜ ì˜¬ë°”ë¥¸ í•™ìŠµ ë°©ë²• (ê°„ë‹¨ ë²„ì „)
ê¸°ì¡´ ì •ìƒ ë¹„ë””ì˜¤ íŒŒì¼ë“¤ì„ ì§ì ‘ ì‚¬ìš©
"""

import os
import torch
import cv2
import numpy as np
from pathlib import Path
from anomalib.models.video import AiVad
from anomalib.engine import Engine
from anomalib.data import Folder
import glob

def create_simple_dataset_from_videos():
    """ê¸°ì¡´ ì •ìƒ ë¹„ë””ì˜¤ íŒŒì¼ë“¤ë¡œ ê°„ë‹¨í•œ ë°ì´í„°ì…‹ ìƒì„±"""
    print("ğŸ“ ê¸°ì¡´ ì •ìƒ ë¹„ë””ì˜¤ íŒŒì¼ë“¤ ê²€ìƒ‰...")
    
    # ì •ìƒ ë¹„ë””ì˜¤ íŒŒì¼ë“¤ ì°¾ê¸°
    video_extensions = ['*.avi', '*.mp4', '*.mov', '*.mkv']
    normal_videos = []
    
    for ext in video_extensions:
        videos = glob.glob(f"normal_*{ext}")
        normal_videos.extend(videos)
    
    print(f"ğŸ“Š ë°œê²¬ëœ ì •ìƒ ë¹„ë””ì˜¤: {len(normal_videos)}ê°œ")
    
    if len(normal_videos) == 0:
        print("âŒ ì •ìƒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return None
    
    # ì²˜ìŒ ëª‡ ê°œë§Œ í‘œì‹œ
    for i, video in enumerate(normal_videos[:5]):
        print(f"  ğŸ¬ {video}")
    
    if len(normal_videos) > 5:
        print(f"  ... ì™¸ {len(normal_videos) - 5}ê°œ")
    
    return normal_videos

def extract_frames_from_videos(video_files, output_dir="extracted_frames"):
    """ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ ì¶”ì¶œ"""
    print(f"\nğŸ“¸ ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ ì¶”ì¶œ: {output_dir}")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    frame_dir = Path(output_dir) / "train" / "good"
    frame_dir.mkdir(parents=True, exist_ok=True)
    
    extracted_count = 0
    
    for i, video_file in enumerate(video_files[:10]):  # ì²˜ìŒ 10ê°œë§Œ ì²˜ë¦¬
        try:
            cap = cv2.VideoCapture(video_file)
            frame_count = 0
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # 5í”„ë ˆì„ë§ˆë‹¤ ì¶”ì¶œ
                if frame_count % 5 == 0:
                    # 224x224ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                    frame_resized = cv2.resize(frame, (224, 224))
                    
                    # íŒŒì¼ëª… ìƒì„±
                    frame_name = f"video_{i:03d}_frame_{frame_count:04d}.jpg"
                    frame_path = frame_dir / frame_name
                    
                    # í”„ë ˆì„ ì €ì¥
                    cv2.imwrite(str(frame_path), frame_resized)
                    extracted_count += 1
                    
                    # ìµœëŒ€ 20í”„ë ˆì„ë§Œ ì¶”ì¶œ
                    if extracted_count >= 20:
                        break
                
                frame_count += 1
            
            cap.release()
            
            if extracted_count >= 20:
                break
                
        except Exception as e:
            print(f"  âš ï¸ {video_file} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    print(f"âœ… ì¶”ì¶œëœ í”„ë ˆì„: {extracted_count}ê°œ")
    return str(Path(output_dir).absolute())

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ AI-VAD ì˜¬ë°”ë¥¸ í•™ìŠµ ë°©ë²• (ê°„ë‹¨ ë²„ì „)")
    print("=" * 50)
    print("ğŸ’¡ í•µì‹¬ ì›ë¦¬:")
    print("   1. Feature Extraction: Flow, Region, Pose, Deep features")
    print("   2. Density Estimation: ì •ìƒ ë°ì´í„°ì˜ ë¶„í¬ í•™ìŠµ")
    print("   3. One-Class Learning: ì •ìƒ ë°ì´í„°ë§Œìœ¼ë¡œ ë¶„í¬ ëª¨ë¸ë§")
    print("   4. No NN Training: ê°€ì¤‘ì¹˜ í•™ìŠµ ì—†ìŒ!")
    print("=" * 50)
    
    # GPU ì„¤ì •
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ–¥ï¸ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    if device == "cuda":
        print(f"GPU: {torch.cuda.get_device_name()}")
    
    # 1. ê¸°ì¡´ ì •ìƒ ë¹„ë””ì˜¤ íŒŒì¼ë“¤ ê²€ìƒ‰
    normal_videos = create_simple_dataset_from_videos()
    if normal_videos is None:
        print("âŒ ì •ìƒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        print("ğŸ’¡ normal_*.avi, normal_*.mp4 íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return
    
    # 2. ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ ì¶”ì¶œ
    dataset_root = extract_frames_from_videos(normal_videos)
    if dataset_root is None:
        print("âŒ í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨")
        return
    
    # 3. AI-VAD ëª¨ë¸ ìƒì„±
    print(f"\nğŸ¤– AI-VAD ëª¨ë¸ ìƒì„±...")
    try:
        model = AiVad(
            # Feature ì¶”ì¶œ ì„¤ì •
            use_velocity_features=True,
            use_pose_features=True,
            use_deep_features=True,
            # Density estimation ì„¤ì •
            n_components_velocity=2,
            n_neighbors_pose=1,
            n_neighbors_deep=1,
        )
        print("âœ… AI-VAD ëª¨ë¸ ìƒì„± ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ AI-VAD ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return
    
    # 4. ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ (ì„ íƒì‚¬í•­)
    checkpoint_path = "aivad_proper_checkpoint.ckpt"
    if os.path.exists(checkpoint_path):
        print(f"\nğŸ”„ ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ: {checkpoint_path}")
        try:
            checkpoint = torch.load(checkpoint_path, weights_only=False)
            if 'state_dict' in checkpoint:
                model.load_state_dict(checkpoint['state_dict'], strict=False)
                print("âœ… ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ")
            else:
                print("âš ï¸ state_dictê°€ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # 5. Anomalib Engine ìƒì„± (AI-VAD ì „ìš© ì„¤ì •)
    print(f"\nğŸ”§ Anomalib Engine ìƒì„±...")
    try:
        engine = Engine(
            devices=1 if device == "cuda" else "auto",
            accelerator="gpu" if device == "cuda" else "cpu",
            precision="32",  # AI-VADëŠ” 32bit ì‚¬ìš©
            # AI-VAD ì „ìš© ì„¤ì •
            max_epochs=1,  # AI-VADëŠ” 1 ì—í¬í¬ë§Œ
            gradient_clip_val=0,  # Gradient clipping ì—†ìŒ
            log_every_n_steps=1,
            enable_progress_bar=True,
            enable_model_summary=False,  # ëª¨ë¸ ìš”ì•½ ë¹„í™œì„±í™”
            num_sanity_val_steps=0,  # ê²€ì¦ ë‹¨ê³„ ì—†ìŒ
        )
        
        print("âœ… Engine ìƒì„± ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ Engine ìƒì„± ì‹¤íŒ¨: {e}")
        return
    
    # 6. Folder ë°ì´í„° ëª¨ë“ˆ ìƒì„± (ì´ë¯¸ì§€ ê¸°ë°˜)
    print(f"\nğŸ“Š Folder ë°ì´í„° ëª¨ë“ˆ ìƒì„±...")
    try:
        datamodule = Folder(
            name="simple_frames",
            root=dataset_root,
            normal_dir="train/good",
            train_batch_size=1,  # ì‘ì€ ë°°ì¹˜ í¬ê¸°
            eval_batch_size=1,
            num_workers=0,
        )
        
        print("âœ… Folder ë°ì´í„° ëª¨ë“ˆ ìƒì„± ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ Folder ë°ì´í„° ëª¨ë“ˆ ìƒì„± ì‹¤íŒ¨: {e}")
        return
    
    # 7. AI-VAD í•™ìŠµ (ì˜¬ë°”ë¥¸ ë°©ë²•)
    print(f"\nğŸ¯ AI-VAD í•™ìŠµ ì‹œì‘...")
    print("ğŸ’¡ í•™ìŠµ ê³¼ì •:")
    print("   1. Feature Extraction: Flow, Region, Pose, Deep features")
    print("   2. Density Update: ì •ìƒ íŠ¹ì„±ë“¤ì„ density estimatorì— ëˆ„ì ")
    print("   3. Density Fit: ëª¨ë“  íŠ¹ì„±ìœ¼ë¡œ ë¶„í¬ ëª¨ë¸ í•™ìŠµ")
    print("   4. No Backpropagation: ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ ì—†ìŒ!")
    
    try:
        # AI-VADì˜ ì˜¬ë°”ë¥¸ í•™ìŠµ ë°©ë²•
        engine.fit(model=model, datamodule=datamodule)
        
        print("âœ… AI-VAD í•™ìŠµ ì™„ë£Œ!")
        
        # Density estimator ìƒíƒœ í™•ì¸
        if hasattr(model.model, 'density_estimator'):
            print(f"ğŸ“Š Density Estimator ìƒíƒœ:")
            print(f"   - ì´ ê°ì§€ ìˆ˜: {model.total_detections}")
            
            # Density estimator fit í˜¸ì¶œ
            if model.total_detections > 0:
                model.fit()  # density estimator í•™ìŠµ
                print("âœ… Density Estimator í•™ìŠµ ì™„ë£Œ")
            else:
                print("âš ï¸ ê°ì§€ëœ ì˜ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"âŒ AI-VAD í•™ìŠµ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # 8. ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    checkpoint_path = "aivad_simple_learned.ckpt"
    try:
        # AI-VAD ëª¨ë¸ ìƒíƒœ ì €ì¥
        torch.save({
            'state_dict': model.state_dict(),
            'pytorch-lightning_version': '2.0.0',
            'model_class': 'AiVad',
            'training_type': 'simple_density_estimation',
            'total_detections': model.total_detections,
        }, checkpoint_path)
        
        print(f"ğŸ’¾ í•™ìŠµëœ ëª¨ë¸ ì €ì¥: {checkpoint_path}")
        print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {os.path.getsize(checkpoint_path) / (1024**2):.1f} MB")
        
    except Exception as e:
        print(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    print("\nğŸ‰ AI-VAD ì˜¬ë°”ë¥¸ í•™ìŠµ ì™„ë£Œ!")
    print("ğŸ’¡ í•™ìŠµëœ ë‚´ìš©:")
    print("1. ì •ìƒ ë°ì´í„°ì˜ Feature ë¶„í¬ í•™ìŠµ")
    print("2. Density Estimatorë¡œ ì´ìƒ íƒì§€ ì¤€ë¹„")
    print("3. UIì—ì„œ 'aivad_simple_learned.ckpt' ë¡œë“œí•˜ì—¬ í…ŒìŠ¤íŠ¸")
    print("4. ë¹„ì •ìƒ ë°ì´í„°ëŠ” ë¶„í¬ì—ì„œ ë²—ì–´ë‚˜ ë†’ì€ ì ìˆ˜")

if __name__ == "__main__":
    main()
