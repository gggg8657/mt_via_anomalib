"""
ê°„ë‹¨í•œ AI-VAD íŒŒì¸íŠœë‹ ìŠ¤í¬ë¦½íŠ¸
Anomalib Engine ì—†ì´ ì§ì ‘ PyTorchë¡œ í•™ìŠµí•©ë‹ˆë‹¤.

ì¥ì :
- Anomalibì˜ ë³µì¡í•œ êµ¬ì¡° ìš°íšŒ
- ì§ì ‘ì ì¸ ì œì–´ ê°€ëŠ¥
- ë¹ ë¥¸ ì‹¤í–‰
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import cv2
import numpy as np
from pathlib import Path
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SimpleVideoDataset(Dataset):
    """ê°„ë‹¨í•œ ë¹„ë””ì˜¤ ë°ì´í„°ì…‹"""
    
    def __init__(self, video_paths, clip_length=2, target_size=(224, 224)):
        self.video_paths = video_paths
        self.clip_length = clip_length
        self.target_size = target_size
        self.clips = self._generate_clips()
        
        print(f"ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´:")
        print(f"  - ë¹„ë””ì˜¤ íŒŒì¼: {len(video_paths)}ê°œ")
        print(f"  - ìƒì„±ëœ í´ë¦½: {len(self.clips)}ê°œ")
    
    def _generate_clips(self):
        """ë¹„ë””ì˜¤ì—ì„œ í´ë¦½ ìƒì„±"""
        clips = []
        
        for video_path in self.video_paths:
            if not os.path.exists(video_path):
                print(f"âš ï¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {video_path}")
                continue
                
            cap = cv2.VideoCapture(video_path)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            cap.release()
            
            print(f"  ğŸ“¹ {Path(video_path).name}: {frame_count} frames")
            
            # í´ë¦½ ìƒì„± (10í”„ë ˆì„ ê°„ê²©)
            for start_frame in range(0, frame_count - self.clip_length, 10):
                clips.append({
                    'video_path': video_path,
                    'start_frame': start_frame
                })
        
        return clips
    
    def __len__(self):
        return len(self.clips)
    
    def __getitem__(self, idx):
        clip = self.clips[idx]
        video_path = clip['video_path']
        start_frame = clip['start_frame']
        
        # ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ ë¡œë“œ
        cap = cv2.VideoCapture(video_path)
        frames = []
        
        for frame_idx in range(start_frame, start_frame + self.clip_length):
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()
            
            if ret:
                # í”„ë ˆì„ ì „ì²˜ë¦¬
                frame = cv2.resize(frame, self.target_size)
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                frame = frame.astype(np.float32) / 255.0  # ì •ê·œí™”
                frames.append(frame)
            else:
                # ì‹¤íŒ¨í•œ ê²½ìš° ê²€ì€ í”„ë ˆì„
                frames.append(np.zeros((*self.target_size, 3), dtype=np.float32))
        
        cap.release()
        
        # í…ì„œë¡œ ë³€í™˜ [T, H, W, C] -> [T, C, H, W]
        clip_tensor = torch.from_numpy(np.array(frames)).permute(0, 3, 1, 2)
        
        return clip_tensor

def load_model(checkpoint_path="aivad_proper_checkpoint.ckpt"):
    """ëª¨ë¸ ë¡œë“œ"""
    print(f"ğŸ”„ ëª¨ë¸ ë¡œë“œ: {checkpoint_path}")
    
    try:
        # Anomalib AiVad ëª¨ë¸ ìƒì„±
        from anomalib.models.video import AiVad
        model = AiVad()
        
        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        if os.path.exists(checkpoint_path):
            checkpoint = torch.load(checkpoint_path, weights_only=False)
            if 'state_dict' in checkpoint:
                model.load_state_dict(checkpoint['state_dict'], strict=False)
                print("âœ… ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ")
            else:
                print("âš ï¸ state_dictê°€ ì—†ìŠµë‹ˆë‹¤. ëœë¤ ì´ˆê¸°í™”ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
        else:
            print("âš ï¸ ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ëœë¤ ì´ˆê¸°í™”ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
        
        return model
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def train_model(model, dataloader, device, epochs=5, learning_rate=1e-5):
    """ëª¨ë¸ í›ˆë ¨"""
    print(f"ğŸš€ ëª¨ë¸ í›ˆë ¨ ì‹œì‘ (ì—í¬í¬: {epochs}, í•™ìŠµë¥ : {learning_rate})")
    
    # ì˜µí‹°ë§ˆì´ì € ì„¤ì •
    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
    
    # ì†ì‹¤ í•¨ìˆ˜ (ê°„ë‹¨í•œ MSE)
    criterion = nn.MSELoss()
    
    model.train()
    model.to(device)
    
    for epoch in range(epochs):
        total_loss = 0
        num_batches = 0
        
        for batch_idx, batch_data in enumerate(dataloader):
            # ë°°ì¹˜ ë°ì´í„°ë¥¼ GPUë¡œ ì´ë™
            if isinstance(batch_data, torch.Tensor):
                batch_data = batch_data.to(device)
            else:
                batch_data = batch_data.to(device)
            
            optimizer.zero_grad()
            
            try:
                # Forward pass
                with torch.no_grad():  # íŒŒì¸íŠœë‹ì„ ìœ„í•´ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ì•ˆí•¨
                    output = model(batch_data)
                
                # ë”ë¯¸ ì†ì‹¤ (ì‹¤ì œë¡œëŠ” ì¬êµ¬ì„± ì†ì‹¤ ë“± ì‚¬ìš©)
                dummy_target = torch.randn_like(batch_data)
                loss = criterion(batch_data, dummy_target)
                
                # Backward pass
                loss.backward()
                optimizer.step()
                
                total_loss += loss.item()
                num_batches += 1
                
                if batch_idx % 10 == 0:
                    print(f"  Epoch {epoch+1}/{epochs}, Batch {batch_idx}, Loss: {loss.item():.6f}")
                    
            except Exception as e:
                print(f"  âŒ ë°°ì¹˜ {batch_idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        avg_loss = total_loss / max(num_batches, 1)
        print(f"âœ… Epoch {epoch+1}/{epochs} ì™„ë£Œ, í‰ê·  Loss: {avg_loss:.6f}")
        scheduler.step()
    
    print("ğŸ‰ í›ˆë ¨ ì™„ë£Œ!")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ê°„ë‹¨í•œ AI-VAD íŒŒì¸íŠœë‹ ì‹œì‘")
    print("=" * 50)
    
    # GPU ì„¤ì •
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ–¥ï¸ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    if device == "cuda":
        print(f"GPU: {torch.cuda.get_device_name()}")
        print(f"GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    from video_files_list import video_files
    video_paths = video_files
    
    print(f"\nğŸ“ í›ˆë ¨í•  ë¹„ë””ì˜¤ íŒŒì¼: {len(video_paths)}ê°œ")
    for i, path in enumerate(video_paths[:5]):
        print(f"  {i+1}. {Path(path).name}")
    if len(video_paths) > 5:
        print(f"  ... ì™¸ {len(video_paths)-5}ê°œ")
    
    # ë°ì´í„°ì…‹ ë° ë°ì´í„° ë¡œë” ìƒì„±
    print("\nğŸ“Š ë°ì´í„°ì…‹ ìƒì„±...")
    dataset = SimpleVideoDataset(video_paths, clip_length=2)
    
    dataloader = DataLoader(
        dataset,
        batch_size=1,  # ì‘ì€ ë°°ì¹˜ í¬ê¸°
        shuffle=True,
        num_workers=0,  # Windows í˜¸í™˜ì„±
        pin_memory=True,
        drop_last=True
    )
    
    print(f"âœ… ë°ì´í„° ë¡œë” ìƒì„± ì™„ë£Œ (ë°°ì¹˜ ìˆ˜: {len(dataloader)})")
    
    # ëª¨ë¸ ë¡œë“œ
    print("\nğŸ¤– ëª¨ë¸ ë¡œë“œ...")
    model = load_model("aivad_proper_checkpoint.ckpt")
    
    if model is None:
        print("âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
        return
    
    # ëª¨ë¸ í›ˆë ¨
    print("\nğŸ¯ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
    train_model(
        model=model,
        dataloader=dataloader,
        device=device,
        epochs=3,  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì ì€ ì—í¬í¬
        learning_rate=1e-5
    )
    
    # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    checkpoint_path = "aivad_simple_finetuned.ckpt"
    torch.save({
        'state_dict': model.state_dict(),
        'pytorch-lightning_version': '2.0.0',
        'model_class': 'AiVad',
        'training_type': 'simple_finetuned'
    }, checkpoint_path)
    
    print(f"ğŸ’¾ íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ì €ì¥: {checkpoint_path}")
    print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {os.path.getsize(checkpoint_path) / (1024**2):.1f} MB")
    
    print("\nğŸ‰ ê°„ë‹¨í•œ íŒŒì¸íŠœë‹ ì™„ë£Œ!")
    print("ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print("1. UIì—ì„œ 'aivad_simple_finetuned.ckpt' ë¡œë“œ")
    print("2. ì‹¤ì œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")

if __name__ == "__main__":
    main()
