"""
AI-VAD ì‹¤ì œ ë¹„ë””ì˜¤ ë°ì´í„°ë¡œ í•™ìŠµ
video_files_list.pyì˜ ì‹¤ì œ ë¹„ë””ì˜¤ íŒŒì¼ë“¤ì„ ì‚¬ìš©
"""

import os
import torch
import cv2
import numpy as np
from pathlib import Path
from anomalib.models.video import AiVad
from anomalib.engine import Engine
from anomalib.data import Avenue
import shutil

# video_files_list.pyì—ì„œ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
def get_video_files():
    """video_files_list.pyì—ì„œ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°"""
    # video_files_list.pyì˜ ë‚´ìš©ì„ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
    video_files = [
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\normal_0.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\normal_1.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\normal_2.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\normal_3.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\normal_4.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\normal_5.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\normal_6.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\normal_7.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\normal_8.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\normal_9.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\normal_10.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\normal_11.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\normal_12.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\normal_13.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\normal_14.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\normal_15.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\normal_16.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\normal_17.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\normal_18.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\normal_19.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\normal_20.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\normal_21.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\normal_22.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_0.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_1.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_2.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_3.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_4.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_5.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_6.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_7.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_8.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_9.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_10.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_11.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_12.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_13.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_14.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_15.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_16.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_17.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_18.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_19.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_20.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_21.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_22.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_23.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_24.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_25.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_26.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_27.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_28.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_29.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_30.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_31.avi",
        "C:\\Users\\User\\PycharmProjects\\pythonProject1\\Accurate-Interpretable-VAD\\data\\my_camera\\training_videos\\rest_32.avi",
    ]
    return video_files

def create_real_video_dataset(video_files, target_dir="real_video_dataset"):
    """ì‹¤ì œ ë¹„ë””ì˜¤ íŒŒì¼ë“¤ì„ AI-VADìš© ë°ì´í„°ì…‹ìœ¼ë¡œ ë³€í™˜"""
    print(f"ğŸ“ ì‹¤ì œ ë¹„ë””ì˜¤ ë°ì´í„°ì…‹ ìƒì„±: {target_dir}")
    
    # Avenue ë°ì´í„°ì…‹ êµ¬ì¡° ìƒì„±
    train_dir = Path(target_dir) / "train" / "normal"
    train_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"  ğŸ“‚ ì •ìƒ ë¹„ë””ì˜¤ í´ë”: {train_dir}")
    
    # ì‹¤ì œ ë¹„ë””ì˜¤ íŒŒì¼ë“¤ ë³µì‚¬
    copied_count = 0
    
    for i, video_file in enumerate(video_files):
        if os.path.exists(video_file):
            # ë¹„ë””ì˜¤ íŒŒì¼ëª… ìƒì„±
            video_name = f"normal_{i:03d}.avi"
            target_path = train_dir / video_name
            
            try:
                # íŒŒì¼ ë³µì‚¬
                shutil.copy2(video_file, target_path)
                copied_count += 1
                
                if copied_count <= 10:  # ì²˜ìŒ 10ê°œë§Œ í‘œì‹œ
                    print(f"    ğŸ¬ {video_name}")
                
            except Exception as e:
                print(f"    âš ï¸ {video_file} ë³µì‚¬ ì‹¤íŒ¨: {e}")
        else:
            print(f"    âš ï¸ íŒŒì¼ ì—†ìŒ: {video_file}")
    
    print(f"  âœ… ë³µì‚¬ëœ ë¹„ë””ì˜¤: {copied_count}ê°œ")
    
    if copied_count == 0:
        print("âŒ ë³µì‚¬ëœ ë¹„ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return None
    
    return str(Path(target_dir).absolute())

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ AI-VAD ì‹¤ì œ ë¹„ë””ì˜¤ ë°ì´í„°ë¡œ í•™ìŠµ")
    print("=" * 60)
    print("ğŸ’¡ ì‹¤ì œ ë¹„ë””ì˜¤ ë°ì´í„° ì‚¬ìš©:")
    print("   1. ì‹¤ì œ ë¹„ë””ì˜¤ íŒŒì¼ë“¤ (56ê°œ)")
    print("   2. AI-VAD ì›ë˜ ë°©ì‹ (Density Estimation)")
    print("   3. ìš°ë¦¬ í™˜ê²½ì˜ ì‹¤ì œ ê°ì²´ë“¤")
    print("   4. ë†’ì€ Domain ì ìš©ì„±")
    print("=" * 60)
    
    # GPU ì„¤ì •
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ–¥ï¸ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    if device == "cuda":
        print(f"GPU: {torch.cuda.get_device_name()}")
    
    # 1. ì‹¤ì œ ë¹„ë””ì˜¤ íŒŒì¼ë“¤ ê°€ì ¸ì˜¤ê¸°
    video_files = get_video_files()
    print(f"\nğŸ“Š ì‹¤ì œ ë¹„ë””ì˜¤ íŒŒì¼: {len(video_files)}ê°œ")
    
    # 2. ì‹¤ì œ ë¹„ë””ì˜¤ ë°ì´í„°ì…‹ ìƒì„±
    dataset_root = create_real_video_dataset(video_files)
    if dataset_root is None:
        print("âŒ ì‹¤ì œ ë¹„ë””ì˜¤ ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨")
        return
    
    # 3. AI-VAD ëª¨ë¸ ìƒì„± (ê°ì²´ ê°ì§€ ê°œì„  ì„¤ì •)
    print(f"\nğŸ¤– AI-VAD ëª¨ë¸ ìƒì„±...")
    try:
        model = AiVad(
            # AI-VAD ì›ë˜ ì„¤ì •
            use_velocity_features=True,
            use_pose_features=True,
            use_deep_features=True,
            # Density estimation ì„¤ì •
            n_components_velocity=2,
            n_neighbors_pose=1,
            n_neighbors_deep=1,
            # ê°ì²´ ê°ì§€ ê°œì„  ì„¤ì •
            box_score_thresh=0.3,  # ë‚®ì¶¤ (0.7 -> 0.3)
            min_bbox_area=50,      # ë‚®ì¶¤ (100 -> 50)
            max_bbox_overlap=0.8,  # ë†’ì„ (0.65 -> 0.8)
            foreground_binary_threshold=10,  # ë‚®ì¶¤ (18 -> 10)
        )
        
        # ëª¨ë¸ì„ GPUë¡œ ì´ë™
        if device == "cuda":
            model = model.to(device)
            print(f"âœ… AI-VAD ëª¨ë¸ ìƒì„± ì™„ë£Œ (GPU: {device})")
        else:
            print("âœ… AI-VAD ëª¨ë¸ ìƒì„± ì™„ë£Œ (CPU)")
        
    except Exception as e:
        print(f"âŒ AI-VAD ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return
    
    # 4. ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
    checkpoint_path = "aivad_proper_checkpoint.ckpt"
    if os.path.exists(checkpoint_path):
        print(f"\nğŸ”„ ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ: {checkpoint_path}")
        try:
            checkpoint = torch.load(checkpoint_path, weights_only=False, map_location=device)
            if 'state_dict' in checkpoint:
                model.load_state_dict(checkpoint['state_dict'], strict=False)
                # ê°€ì¤‘ì¹˜ ë¡œë“œ í›„ì—ë„ ëª¨ë¸ì„ GPUë¡œ ì´ë™
                if device == "cuda":
                    model = model.to(device)
                print("âœ… ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ")
            else:
                print("âš ï¸ state_dictê°€ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # 5. Anomalib Engine ìƒì„± (AI-VAD ì „ìš© ì„¤ì •)
    print(f"\nğŸ”§ Anomalib Engine ìƒì„±...")
    try:
        engine = Engine(
            devices=1 if device == "cuda" else "auto",
            accelerator="gpu" if device == "cuda" else "cpu",
            precision="32",  # AI-VADëŠ” 32bit ì‚¬ìš©
            # AI-VAD ì „ìš© ì„¤ì •
            max_epochs=1,  # AI-VADëŠ” 1 ì—í¬í¬ë§Œ
            gradient_clip_val=0,  # Gradient clipping ì—†ìŒ
            log_every_n_steps=1,
            enable_progress_bar=True,
            enable_model_summary=False,  # ëª¨ë¸ ìš”ì•½ ë¹„í™œì„±í™”
            num_sanity_val_steps=0,  # ê²€ì¦ ë‹¨ê³„ ì—†ìŒ
        )
        
        print("âœ… Engine ìƒì„± ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ Engine ìƒì„± ì‹¤íŒ¨: {e}")
        return
    
    # 6. ì§ì ‘ì ì¸ ë¹„ë””ì˜¤ ì²˜ë¦¬ ë°©ì‹ (Avenue ëŒ€ì‹ )
    print(f"\nğŸ“Š ì§ì ‘ì ì¸ ë¹„ë””ì˜¤ ì²˜ë¦¬ ë°©ì‹ ì‚¬ìš©...")
    print("ğŸ’¡ Avenue ë°ì´í„° ëª¨ë“ˆ ëŒ€ì‹  ì§ì ‘ ë¹„ë””ì˜¤ ì²˜ë¦¬")
    
    # ë¹„ë””ì˜¤ íŒŒì¼ë“¤ ì§ì ‘ ì²˜ë¦¬
    video_files_available = []
    train_dir = Path(dataset_root) / "train" / "normal"
    
    for video_file in train_dir.glob("*.avi"):
        if video_file.exists():
            video_files_available.append(str(video_file))
    
    print(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ë¹„ë””ì˜¤: {len(video_files_available)}ê°œ")
    
    if len(video_files_available) == 0:
        print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ë¹„ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    # 7. AI-VAD ì§ì ‘ í•™ìŠµ (ë¹„ë””ì˜¤ íŒŒì¼ë“¤ ì§ì ‘ ì²˜ë¦¬)
    print(f"\nğŸ¯ AI-VAD ì§ì ‘ í•™ìŠµ ì‹œì‘...")
    print("ğŸ’¡ í•™ìŠµ ê³¼ì •:")
    print("   1. ì‹¤ì œ ë¹„ë””ì˜¤ íŒŒì¼ë“¤ ì§ì ‘ ë¡œë“œ")
    print("   2. Feature Extraction: Flow, Region, Pose, Deep features")
    print("   3. Density Update: ì •ìƒ íŠ¹ì„±ë“¤ì„ density estimatorì— ëˆ„ì ")
    print("   4. Density Fit: ëª¨ë“  íŠ¹ì„±ìœ¼ë¡œ ë¶„í¬ ëª¨ë¸ í•™ìŠµ")
    print("   5. No Backpropagation: ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ ì—†ìŒ!")
    print("   6. ìš°ë¦¬ í™˜ê²½ì˜ ì‹¤ì œ ê°ì²´ë“¤ í•™ìŠµ!")
    
    try:
        # ì§ì ‘ì ì¸ ë¹„ë””ì˜¤ ì²˜ë¦¬ ë° AI-VAD í•™ìŠµ
        model.model.eval()  # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
        
        # ëª¨ë¸ì´ GPUì— ìˆëŠ”ì§€ í™•ì¸
        print(f"ğŸ” ëª¨ë¸ ë””ë°”ì´ìŠ¤ í™•ì¸:")
        print(f"   - ëª¨ë¸ ë””ë°”ì´ìŠ¤: {next(model.model.parameters()).device}")
        print(f"   - íƒ€ê²Ÿ ë””ë°”ì´ìŠ¤: {device}")
        
        if device == "cuda" and next(model.model.parameters()).device.type != "cuda":
            print("âš ï¸ ëª¨ë¸ì„ GPUë¡œ ì´ë™ ì¤‘...")
            model.model = model.model.to(device)
        
        total_clips_processed = 0
        total_detections = 0
        
        for i, video_path in enumerate(video_files_available[:10]):  # ì²˜ìŒ 10ê°œë§Œ ì²˜ë¦¬
            print(f"\nğŸ“¹ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘: {i+1}/{min(10, len(video_files_available))}")
            print(f"   íŒŒì¼: {Path(video_path).name}")
            
            try:
                # ë¹„ë””ì˜¤ ë¡œë“œ
                cap = cv2.VideoCapture(video_path)
                if not cap.isOpened():
                    print(f"   âš ï¸ ë¹„ë””ì˜¤ ì—´ê¸° ì‹¤íŒ¨: {video_path}")
                    continue
                
                frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                fps = cap.get(cv2.CAP_PROP_FPS)
                
                print(f"   ğŸ“Š í”„ë ˆì„ ìˆ˜: {frame_count}, FPS: {fps:.1f}")
                
                # 2í”„ë ˆì„ì”© í´ë¦½ìœ¼ë¡œ ì²˜ë¦¬
                clip_count = 0
                frame_buffer = []
                
                while True:
                    ret, frame = cap.read()
                    if not ret:
                        break
                    
                    # í”„ë ˆì„ ì „ì²˜ë¦¬
                    frame_resized = cv2.resize(frame, (224, 224))
                    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
                    frame_tensor = torch.from_numpy(frame_rgb).float() / 255.0
                    frame_tensor = frame_tensor.permute(2, 0, 1)  # HWC -> CHW
                    
                    frame_buffer.append(frame_tensor)
                    
                    # 2í”„ë ˆì„ì´ ëª¨ì´ë©´ í´ë¦½ ì²˜ë¦¬
                    if len(frame_buffer) == 2:
                        try:
                            # ë¹„ë””ì˜¤ í´ë¦½ ìƒì„± [2, 3, 224, 224]
                            video_clip = torch.stack(frame_buffer).unsqueeze(0)  # [1, 2, 3, 224, 224]
                            
                            # ë””ë°”ì´ìŠ¤ í™•ì¸ ë° ì´ë™
                            if device == "cuda":
                                video_clip = video_clip.to(device)
                            
                            # AI-VAD ì¶”ë¡  (í•™ìŠµ ëª¨ë“œ)
                            with torch.no_grad():
                                try:
                                    output = model.model(video_clip)
                                    
                                    # ì¶œë ¥ êµ¬ì¡° í™•ì¸
                                    if isinstance(output, list) and len(output) > 0:
                                        # íŠ¹ì„± ì¶”ì¶œ ë° density estimator ì—…ë°ì´íŠ¸
                                        if hasattr(model.model, 'density_estimator'):
                                            # AI-VADì˜ ë‚´ë¶€ íŠ¹ì„±ë“¤ì„ density estimatorì— ì¶”ê°€
                                            model.model.density_estimator.update(output)
                                            total_detections += 1
                                    else:
                                        # ì¶œë ¥ì´ ë¹„ì–´ìˆê±°ë‚˜ ì˜ˆìƒê³¼ ë‹¤ë¦„
                                        if clip_count == 0:  # ì²« ë²ˆì§¸ í´ë¦½ì—ì„œë§Œ ì¶œë ¥
                                            print(f"   âš ï¸ AI-VAD ì¶œë ¥ì´ ë¹„ì–´ìˆê±°ë‚˜ ì˜ˆìƒê³¼ ë‹¤ë¦„: {type(output)}")
                                        
                                except Exception as e:
                                    if "index 0 is out of bounds" in str(e):
                                        # Region Extractorì—ì„œ ê°ì²´ ê°ì§€ ì‹¤íŒ¨
                                        if clip_count == 0:  # ì²« ë²ˆì§¸ í´ë¦½ì—ì„œë§Œ ì¶œë ¥
                                            print(f"   âš ï¸ ê°ì²´ ê°ì§€ ì‹¤íŒ¨: Region Extractorê°€ ê°ì²´ë¥¼ ì°¾ì§€ ëª»í•¨")
                                    else:
                                        print(f"   âš ï¸ AI-VAD ì¶”ë¡  ì‹¤íŒ¨: {e}")
                                    continue
                            
                            clip_count += 1
                            total_clips_processed += 1
                            
                            if clip_count % 10 == 0:
                                print(f"   âœ… ì²˜ë¦¬ëœ í´ë¦½: {clip_count}")
                            
                        except Exception as e:
                            # ì²« ë²ˆì§¸ í´ë¦½ì—ì„œë§Œ ìƒì„¸ ì—ëŸ¬ ì¶œë ¥
                            if clip_count == 0:
                                print(f"   âš ï¸ í´ë¦½ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                        
                        # ë²„í¼ì—ì„œ ì²« ë²ˆì§¸ í”„ë ˆì„ ì œê±°
                        frame_buffer.pop(0)
                
                cap.release()
                print(f"   âœ… ì™„ë£Œ: {clip_count}ê°œ í´ë¦½ ì²˜ë¦¬")
                
            except Exception as e:
                print(f"   âŒ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        print(f"\nğŸ“Š ì „ì²´ ì²˜ë¦¬ ê²°ê³¼:")
        print(f"   - ì²˜ë¦¬ëœ ë¹„ë””ì˜¤: {min(10, len(video_files_available))}ê°œ")
        print(f"   - ì²˜ë¦¬ëœ í´ë¦½: {total_clips_processed}ê°œ")
        print(f"   - ì´ ê°ì§€ ìˆ˜: {total_detections}ê°œ")
        
        # Density estimator ìµœì¢… í•™ìŠµ
        if hasattr(model.model, 'density_estimator') and total_detections > 0:
            print(f"\nğŸ”§ Density Estimator ìµœì¢… í•™ìŠµ...")
            model.model.density_estimator.fit()
            print("âœ… Density Estimator í•™ìŠµ ì™„ë£Œ")
        else:
            print("âš ï¸ ê°ì§€ëœ íŠ¹ì„±ì´ ì—†ì–´ density estimator í•™ìŠµì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            print("ğŸ’¡ í•´ê²° ë°©ë²•:")
            print("   1. ë¹„ë””ì˜¤ì— ì›€ì§ì´ëŠ” ê°ì²´ê°€ ìˆëŠ”ì§€ í™•ì¸")
            print("   2. ì¡°ëª…ì´ ì¶©ë¶„í•œì§€ í™•ì¸")
            print("   3. ê°ì²´ê°€ ì¶©ë¶„íˆ í°ì§€ í™•ì¸ (ìµœì†Œ 50x50 í”½ì…€)")
            print("   4. AI-VAD íŒŒë¼ë¯¸í„°ë¥¼ ë” ë‚®ì¶¤ (box_score_thresh=0.1)")
        
        print("âœ… AI-VAD ì§ì ‘ í•™ìŠµ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ AI-VAD ì§ì ‘ í•™ìŠµ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # 8. ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    checkpoint_path = "aivad_real_videos_learned.ckpt"
    try:
        # AI-VAD ëª¨ë¸ ìƒíƒœ ì €ì¥
        torch.save({
            'state_dict': model.state_dict(),
            'pytorch-lightning_version': '2.0.0',
            'model_class': 'AiVad',
            'training_type': 'real_videos_direct_processing',
            'total_clips_processed': total_clips_processed,
            'total_detections': total_detections,
        }, checkpoint_path)
        
        print(f"ğŸ’¾ í•™ìŠµëœ ëª¨ë¸ ì €ì¥: {checkpoint_path}")
        print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {os.path.getsize(checkpoint_path) / (1024**2):.1f} MB")
        
    except Exception as e:
        print(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    print("\nğŸ‰ AI-VAD ì‹¤ì œ ë¹„ë””ì˜¤ í•™ìŠµ ì™„ë£Œ!")
    print("ğŸ’¡ í•™ìŠµëœ ë‚´ìš©:")
    print("1. ì‹¤ì œ ë¹„ë””ì˜¤ íŒŒì¼ë“¤ë¡œ í•™ìŠµ")
    print("2. ìš°ë¦¬ í™˜ê²½ì˜ ì‹¤ì œ ê°ì²´ë“¤")
    print("3. ë†’ì€ Domain ì ìš©ì„±")
    print("4. ì •ìƒ ë°ì´í„°ì˜ Feature ë¶„í¬ í•™ìŠµ")
    print("5. Density Estimatorë¡œ ì´ìƒ íƒì§€ ì¤€ë¹„")
    print("6. UIì—ì„œ 'aivad_real_videos_learned.ckpt' ë¡œë“œí•˜ì—¬ í…ŒìŠ¤íŠ¸")
    print("7. ë¹„ì •ìƒ ë°ì´í„°ëŠ” ë¶„í¬ì—ì„œ ë²—ì–´ë‚˜ ë†’ì€ ì ìˆ˜")

if __name__ == "__main__":
    main()
