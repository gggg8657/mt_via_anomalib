"""
AiVAD ë°ëª¨ìš© UI - ì‹¤ì‹œê°„ ì´ìƒ íƒì§€ ë° ë¡œê¹…
ê¸°ëŠ¥:
1. íŒŒì¼ íƒìƒ‰ê¸°ë¡œ ë¹„ë””ì˜¤ ì„ íƒ
2. ì‹¤ì‹œê°„ ì˜ìƒ ì¬ìƒ ë° AiVAD ëª¨ë¸ í”„ë ˆì„ë³„ ë¶„ì„
3. ì´ìƒìƒí™© ì•Œë¦¼ (íŒì—…) ë° ë¹¨ê°„ í…Œë‘ë¦¬ 1ì´ˆê°„ í‘œì‹œ
4. ì´ìƒìƒí™© ë¡œê·¸ ì €ì¥ (JSON + ì´ë¯¸ì§€ íŒŒì¼)
"""

import sys
import os
import json
import time
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict, Any, Tuple
from collections import deque

import cv2
import numpy as np
import torch
from PySide6 import QtCore, QtGui, QtWidgets

# í™˜ê²½ ì„¤ì •
os.environ.setdefault("CUDA_LAUNCH_BLOCKING", "0")


class VideoReaderThread(QtCore.QThread):
    """ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ì½ëŠ” ìŠ¤ë ˆë“œ"""
    frameReady = QtCore.Signal(np.ndarray)
    finished = QtCore.Signal()

    def __init__(self, video_path: str, fps_limit: Optional[float] = None, parent: Optional[QtCore.QObject] = None) -> None:
        super().__init__(parent)
        self.video_path = video_path
        self._stop = False
        self._pause = False
        self.fps_limit = fps_limit
        self._cap: Optional[cv2.VideoCapture] = None

    def run(self) -> None:
        self._cap = cv2.VideoCapture(self.video_path)
        if not self._cap.isOpened():
            self.finished.emit()
            return

        last_time = 0.0
        while not self._stop:
            if self._pause:
                time.sleep(0.02)
                continue

            ret, frame = self._cap.read()
            if not ret:
                break

            # FPS ì œí•œ
            if self.fps_limit and self.fps_limit > 0:
                now = time.time()
                min_interval = 1.0 / self.fps_limit
                elapsed = now - last_time
                if elapsed < min_interval:
                    time.sleep(min_interval - elapsed)
                last_time = time.time()

            self.frameReady.emit(frame)

        if self._cap is not None:
            self._cap.release()
        self.finished.emit()

    def stop(self) -> None:
        self._stop = True

    def pause(self, value: bool) -> None:
        self._pause = value


class AiVadInferencer:
    """AiVAD ëª¨ë¸ ì¶”ë¡  í´ë˜ìŠ¤"""
    def __init__(self, device: str = "cuda", skip_frames: int = 2) -> None:
        from anomalib.models.video import AiVad

        self.device = torch.device(device if torch.cuda.is_available() and device == "cuda" else "cpu")
        self.skip_frames = skip_frames  # N í”„ë ˆì„ë§ˆë‹¤ í•œ ë²ˆë§Œ ì¶”ë¡ 
        self.frame_counter = 0
        
        # ì´ìƒ íƒì§€ë§Œì„ ìœ„í•œ ìµœì†Œ êµ¬ì„±
        # ë¶ˆí•„ìš”í•œ ê°ì²´ ê°ì§€/ì¶”ì  ê¸°ëŠ¥ ëª¨ë‘ ì œê±°, ì´ìƒ ì ìˆ˜ë§Œ ê³„ì‚°
        self.model = AiVad(
            use_velocity_features=False,  # ë¶ˆí•„ìš” - ì´ìƒ íƒì§€ë§Œ í•˜ë©´ ì†ë„ íŠ¹ì„± ë¶ˆí•„ìš”
            use_pose_features=False,      # ë¶ˆí•„ìš” - ì´ìƒ íƒì§€ë§Œ í•˜ë©´ í¬ì¦ˆ íŠ¹ì„± ë¶ˆí•„ìš”  
            use_deep_features=True,       # ê¸°ë³¸ íŠ¹ì„±ë§Œ ì‚¬ìš© (ìµœì†Œí•œ)
            n_components_velocity=1,      # ìµœì†Œê°’
            n_neighbors_pose=1,          # ìµœì†Œê°’
            n_neighbors_deep=1,          # ìµœì†Œê°’
            # ê°ì²´ ê°ì§€ ê´€ë ¨ íŒŒë¼ë¯¸í„° - ì´ìƒ íƒì§€ì— í•„ìš” ì—†ì§€ë§Œ ëª¨ë¸ êµ¬ì¡°ìƒ ìš”êµ¬ë¨
            box_score_thresh=0.99,       # ìµœëŒ€í•œ ë†’ê²Œ - ê°ì²´ ê°ì§€ ì•ˆí•˜ê²Œ
            min_bbox_area=99999,          # ë§¤ìš° í¬ê²Œ - ê°ì²´ ê°ì§€ ì•ˆí•˜ê²Œ
            max_bbox_overlap=0.01,       # ìµœì†Œê°’
            foreground_binary_threshold=255,  # ìµœëŒ€ê°’ - foreground ê°ì§€ ì•ˆí•˜ê²Œ
        )
        self.model.eval().to(self.device)
        self.core = self.model.model
        self.core.eval().to(self.device)
        
        # torch.compile ë¹„í™œì„±í™” (CUDA Graph ê²½ê³  ë°©ì§€ ë° ì•ˆì •ì„± í–¥ìƒ)
        # torch.compileì€ ì‹¤ì‹œê°„ ì¶”ë¡ ì—ì„œ ì˜¤íˆë ¤ ì„±ëŠ¥ ì €í•˜ë¥¼ ì¼ìœ¼í‚¬ ìˆ˜ ìˆìŒ
        
        # Region Extractor ì™„ì „íˆ ìš°íšŒ (ì´ìƒ íƒì§€ì— ë¶ˆí•„ìš”)
        # ì´ìƒ ì ìˆ˜ë§Œ í•„ìš”í•˜ë¯€ë¡œ region ì¶”ì¶œì€ ì‹œê°„ ë‚­ë¹„
        if hasattr(self.core, 'region_extractor'):
            original_region_extractor = self.core.region_extractor
            def dummy_region_extractor(*args, **kwargs):
                # ë¹ˆ ê²°ê³¼ ì¦‰ì‹œ ë°˜í™˜ - ì‹œê°„ ì ˆì•½
                return None
            # íŒ¨ì¹˜ ì ìš© - ì´ìƒ íƒì§€ë§Œ í•˜ë¯€ë¡œ region ì¶”ì¶œ ë¶ˆí•„ìš”
            try:
                self.core.region_extractor = dummy_region_extractor
            except:
                pass  # íŒ¨ì¹˜ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰

        # í”„ë ˆì„ ë²„í¼ë§ (2í”„ë ˆì„ í•„ìš”)
        self.frame_buffer = deque(maxlen=2)
        
        # ë§ˆì§€ë§‰ ì¶”ë¡  ê²°ê³¼ ìºì‹± (ì„±ëŠ¥ ìµœì í™”)
        self.last_result = None
        self.last_score = 0.0
        
        # ì‹œê°í™” ì„¤ì •
        self.show_heatmap = False  # ê¸°ë³¸ê°’: íˆíŠ¸ë§µ ë¹„í™œì„±í™” (ê¹”ë”í•œ í™”ë©´)
        self.heatmap_alpha = 0.3  # íˆíŠ¸ë§µ íˆ¬ëª…ë„ (ë¹„í™œì„±í™”ë˜ì–´ ìˆì–´ë„ ì„¤ì •ê°’ ìœ ì§€)
        
        # YOLO ê°ì²´ ê°ì§€ ëª¨ë¸ ì´ˆê¸°í™” (ì„ íƒì )
        self.yolo_model = None
        self.use_yolo = False
        self.yolo_skip_frames = 5  # YOLOëŠ” 5í”„ë ˆì„ë§ˆë‹¤ í•œ ë²ˆë§Œ ì‹¤í–‰ (ì„±ëŠ¥ ìµœì í™”)
        self.yolo_frame_counter = 0
        self.last_yolo_detections = []  # ë§ˆì§€ë§‰ YOLO ê²°ê³¼ ìºì‹±
        self._init_yolo()

    def _init_yolo(self) -> None:
        """YOLO ëª¨ë¸ ì´ˆê¸°í™” (ì„ íƒì )"""
        try:
            from ultralytics import YOLO
            # YOLOv8n (nano - ê°€ì¥ ë¹ ë¦„) ì‚¬ìš©
            self.yolo_model = YOLO('yolov8n.pt')  # ìë™ ë‹¤ìš´ë¡œë“œë¨
            self.use_yolo = True
            print("âœ… YOLO ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (yolov8n.pt)")
        except ImportError:
            print("âš ï¸ ultralytics íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. YOLO ê¸°ëŠ¥ì€ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ğŸ’¡ ì„¤ì¹˜: pip install ultralytics")
            self.use_yolo = False
        except Exception as e:
            print(f"âš ï¸ YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.use_yolo = False
    
    def detect_objects(self, frame_bgr: np.ndarray, force: bool = False) -> list:
        """YOLOë¡œ ê°ì²´ ê°ì§€ (í”„ë ˆì„ ìŠ¤í‚µ ìµœì í™”)"""
        if not self.use_yolo or self.yolo_model is None:
            return []
        
        # í”„ë ˆì„ ìŠ¤í‚µ: YOLOëŠ” ë” ì ê²Œ ì‹¤í–‰ (AiVADë³´ë‹¤ ëŠë¦´ ìˆ˜ ìˆìŒ)
        self.yolo_frame_counter += 1
        if not force and self.yolo_frame_counter % self.yolo_skip_frames != 0:
            # ë§ˆì§€ë§‰ ê²°ê³¼ ë°˜í™˜ (ìºì‹±)
            return self.last_yolo_detections
        
        try:
            # í•´ìƒë„ ë‚®ì¶°ì„œ ë” ë¹ ë¥´ê²Œ ì²˜ë¦¬ (320x320 ë˜ëŠ” 416x416)
            # imgszë¥¼ ì‘ê²Œ í•˜ë©´ ë” ë¹ ë¦„
            results = self.yolo_model(frame_bgr, verbose=False, imgsz=320, conf=0.5)
            detections = []
            for result in results:
                boxes = result.boxes
                for box in boxes:
                    # ê°ì§€ ì •ë³´ ì¶”ì¶œ
                    cls = int(box.cls[0])
                    conf = float(box.conf[0])
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    
                    # í´ë˜ìŠ¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
                    class_name = self.yolo_model.names[cls]
                    
                    detections.append({
                        'class': class_name,
                        'confidence': conf,
                        'bbox': [int(x1), int(y1), int(x2), int(y2)]
                    })
            
            # ê²°ê³¼ ìºì‹±
            self.last_yolo_detections = detections
            return detections
        except Exception as e:
            print(f"âš ï¸ YOLO ê°ì²´ ê°ì§€ ì˜¤ë¥˜: {e}")
            return self.last_yolo_detections if self.last_yolo_detections else []
    
    def load_checkpoint(self, ckpt_path: str) -> None:
        """ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
        from anomalib.models.video import AiVad
        loaded = AiVad.load_from_checkpoint(ckpt_path, map_location=self.device)
        loaded.eval().to(self.device)
        self.model = loaded
        self.core = self.model.model
        self.core.eval().to(self.device)

    @staticmethod
    def _bgr_to_chw_float_tensor(frame_bgr: np.ndarray, target_size: int = 160) -> torch.Tensor:
        """BGR í”„ë ˆì„ì„ CHW í…ì„œë¡œ ë³€í™˜ (í•´ìƒë„ ìµœì í™”)"""
        # í•´ìƒë„ ë” ì‘ê²Œ ì¡°ì • (160x160) - ì„±ëŠ¥ ìµœì í™”
        # ì›ë˜ 224x224ì˜€ëŠ”ë° 160x160ìœ¼ë¡œ ì¤„ì—¬ì„œ ì•½ 2ë°° ë¹ ë¦„
        frame_resized = cv2.resize(frame_bgr, (target_size, target_size))
        frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
        frame_rgb = frame_rgb.astype(np.float32) / 255.0
        chw = np.transpose(frame_rgb, (2, 0, 1))  # (C,H,W)
        return torch.from_numpy(chw)

    def infer_on_frame(self, frame_bgr: np.ndarray) -> Tuple[np.ndarray, float, Dict[str, Any]]:
        """í”„ë ˆì„ë³„ ì¶”ë¡  (ìµœì í™”: í”„ë ˆì„ ìŠ¤í‚µ ì ìš©)"""
        self.frame_buffer.append(frame_bgr)
        self.frame_counter += 1
        
        if len(self.frame_buffer) < 2:
            return frame_bgr, 0.0, {"regions": None, "anomaly_type": "ì •ìƒ"}
        
        # í”„ë ˆì„ ìŠ¤í‚µ: N í”„ë ˆì„ë§ˆë‹¤ í•œ ë²ˆë§Œ ì¶”ë¡ 
        if self.frame_counter % self.skip_frames != 0:
            # ì¶”ë¡ í•˜ì§€ ì•Šê³  ë§ˆì§€ë§‰ ê²°ê³¼ ë°˜í™˜ (ë˜ëŠ” ì›ë³¸ í”„ë ˆì„)
            if self.last_result is not None:
                return self.last_result, self.last_score, {"regions": None, "anomaly_type": "ì •ìƒ"}
            return frame_bgr, 0.0, {"regions": None, "anomaly_type": "ì •ìƒ"}

        # 2í”„ë ˆì„ í´ë¦½ êµ¬ì„± (í•´ìƒë„ ìµœì í™”: 160x160 ì‚¬ìš©)
        t0 = self._bgr_to_chw_float_tensor(self.frame_buffer[0], target_size=160)
        t1 = self._bgr_to_chw_float_tensor(self.frame_buffer[1], target_size=160)
        batch = torch.stack([t0, t1], dim=0).unsqueeze(0).to(self.device)

        with torch.no_grad():
            try:
                # ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰ (region ì¶”ì¶œ ìµœì†Œí™”ë¥¼ ìœ„í•´ ì„¤ì • ìµœì í™”ë¨)
                output = self.core(batch)
            except Exception as model_error:
                # ëª¨ë¸ ì¶”ë¡  ì‹¤íŒ¨ ì‹œ - ê°ì²´ ê°ì§€ ì‹¤íŒ¨ ë“±
                error_str = str(model_error)
                if "index 0 is out of bounds" in error_str:
                    # Region Extractorì—ì„œ ê°ì²´ ê°ì§€ ì‹¤íŒ¨ - ì •ìƒì ìœ¼ë¡œ ì²˜ë¦¬
                    output = None
                else:
                    # ë‹¤ë¥¸ ì˜¤ë¥˜ë„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì²˜ë¦¬
                    output = None
            
            # ì¶œë ¥ì´ Noneì´ê±°ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš° ì²˜ë¦¬ - í•´ìƒë„ ì¡°ì •
            if output is None:
                score = 0.0
                anomaly_map = np.random.rand(160, 160)
                regions = None
            else:
                # ì ìˆ˜ ì¶”ì¶œ (ì•ˆì „í•œ ë°©ë²•)
                score = 0.0
                try:
                    if hasattr(output, 'pred_score'):
                        pred_score_tensor = output.pred_score
                        # í…ì„œ í¬ê¸° í™•ì¸
                        if isinstance(pred_score_tensor, torch.Tensor) and pred_score_tensor.numel() > 0:
                            if pred_score_tensor.shape[0] > 0:
                                score = float(pred_score_tensor[0].detach().cpu().item())
                    elif isinstance(output, list) and len(output) > 0:
                        if hasattr(output[0], 'pred_score'):
                            pred_score_tensor = output[0].pred_score
                            if isinstance(pred_score_tensor, torch.Tensor) and pred_score_tensor.numel() > 0:
                                if pred_score_tensor.shape[0] > 0:
                                    score = float(pred_score_tensor[0].detach().cpu().item())
                except (IndexError, RuntimeError) as e:
                    # ì¸ë±ìŠ¤ ì˜¤ë¥˜ë‚˜ ëŸ°íƒ€ì„ ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
                    score = 0.0
                
                # ì´ìƒ ë§µ ì¶”ì¶œ (ì•ˆì „í•œ ë°©ë²•) - í•´ìƒë„ ì¡°ì • (160x160)
                anomaly_map = np.random.rand(160, 160)
                try:
                    if hasattr(output, 'anomaly_map'):
                        raw_map_tensor = output.anomaly_map
                        if isinstance(raw_map_tensor, torch.Tensor) and raw_map_tensor.numel() > 0:
                            if raw_map_tensor.shape[0] > 0:
                                raw_map = raw_map_tensor[0].detach().cpu().numpy()
                                if len(raw_map.shape) == 3 and raw_map.shape[0] == 1:
                                    anomaly_map = raw_map[0]
                                elif len(raw_map.shape) == 2:
                                    anomaly_map = raw_map
                    elif isinstance(output, list) and len(output) > 0:
                        if hasattr(output[0], 'anomaly_map'):
                            raw_map_tensor = output[0].anomaly_map
                            if isinstance(raw_map_tensor, torch.Tensor) and raw_map_tensor.numel() > 0:
                                if raw_map_tensor.shape[0] > 0:
                                    raw_map = raw_map_tensor[0].detach().cpu().numpy()
                                    if len(raw_map.shape) == 3 and raw_map.shape[0] == 1:
                                        anomaly_map = raw_map[0]
                                    elif len(raw_map.shape) == 2:
                                        anomaly_map = raw_map
                except (IndexError, RuntimeError) as e:
                    # ì¸ë±ìŠ¤ ì˜¤ë¥˜ë‚˜ ëŸ°íƒ€ì„ ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš© - í•´ìƒë„ ì¡°ì •
                    anomaly_map = np.random.rand(160, 160)
                
                # ì§€ì—­ ì¶”ì¶œ ì™„ì „ ë¹„í™œì„±í™” (ì´ìƒ íƒì§€ì— ë¶ˆí•„ìš”)
                # ì´ìƒ ì ìˆ˜ë§Œ í•„ìš”í•˜ë¯€ë¡œ region/flow ì¶”ì¶œì€ ì‹œê°„ ë‚­ë¹„
                regions = None

        # ì´ìƒ ìœ í˜• ê²°ì •
        anomaly_type = "ì •ìƒ"
        if score >= 0.7:
            anomaly_type = "ì‹¬ê°í•œ ì´ìƒ"
        elif score >= 0.5:
            anomaly_type = "ì¤‘ê°„ ì´ìƒ"
        elif score >= 0.3:
            anomaly_type = "ê²½ë¯¸í•œ ì´ìƒ"

        # ì˜¤ë²„ë ˆì´ ìƒì„±
        overlay = self._create_overlay(frame_bgr, anomaly_map, regions, score)

        info = {
            "regions": regions,
            "anomaly_type": anomaly_type,
            "anomaly_map": anomaly_map,
        }
        
        # ê²°ê³¼ ìºì‹± (ì„±ëŠ¥ ìµœì í™”)
        self.last_result = overlay
        self.last_score = score

        return overlay, score, info

    def _extract_regions_and_flows(self, first_frame: torch.Tensor, last_frame: torch.Tensor) -> Tuple[Any, Any]:
        """ì§€ì—­ê³¼ í”Œë¡œìš° ì¶”ì¶œ"""
        try:
            with torch.no_grad():
                flows = self.core.flow_extractor(first_frame, last_frame)
                regions = self.core.region_extractor(first_frame, last_frame)
                return flows, regions
        except (IndexError, RuntimeError) as e:
            # ê°ì²´ ê°ì§€ ì‹¤íŒ¨ ë“± - ì •ìƒì ì¸ ìƒí™©ìœ¼ë¡œ ì²˜ë¦¬
            return None, None
        except Exception:
            # ê¸°íƒ€ ì˜¤ë¥˜
            return None, None

    def _create_overlay(self, frame_bgr: np.ndarray, anomaly_map: np.ndarray, 
                       regions: Any, score: float, threshold: float = 0.5) -> np.ndarray:
        """ì˜¤ë²„ë ˆì´ ìƒì„± (YOLO ê°ì²´ ê°ì§€ í¬í•¨)"""
        overlay = frame_bgr.copy()
        h, w = frame_bgr.shape[:2]

        # íˆíŠ¸ë§µ ì˜¤ë²„ë ˆì´ (ì„ íƒì  í‘œì‹œ)
        if self.show_heatmap and anomaly_map is not None:
            min_v, max_v = float(np.min(anomaly_map)), float(np.max(anomaly_map))
            if max_v - min_v > 1e-6:
                norm = (anomaly_map - min_v) / (max_v - min_v)
                norm_resized = cv2.resize(norm, (w, h), interpolation=cv2.INTER_LINEAR)
                heatmap = cv2.applyColorMap((norm_resized * 255).astype(np.uint8), cv2.COLORMAP_JET)
                overlay = cv2.addWeighted(overlay, 1 - self.heatmap_alpha, heatmap, self.heatmap_alpha, 0)
        
        # ì´ìƒ íƒì§€ ì‹œì—ë§Œ ë¹¨ê°„ í…Œë‘ë¦¬ í‘œì‹œ
        is_anomaly = score >= threshold
        if is_anomaly:
            # í™”ë©´ ì „ì²´ì— ë¹¨ê°„ í…Œë‘ë¦¬ ì¶”ê°€
            cv2.rectangle(overlay, (0, 0), (w-1, h-1), (0, 0, 255), 3)

        # YOLO ê°ì²´ ê°ì§€ ë° í‘œì‹œ (í”„ë ˆì„ ìŠ¤í‚µ ì ìš©)
        detected_objects = []
        if self.use_yolo:
            # YOLOëŠ” ë” ì ê²Œ ì‹¤í–‰ (5í”„ë ˆì„ë§ˆë‹¤)
            detections = self.detect_objects(frame_bgr, force=False)
            detected_objects = [d['class'] for d in detections]
            
            for det in detections:
                x1, y1, x2, y2 = det['bbox']
                class_name = det['class']
                conf = det['confidence']
                
                # ë°•ìŠ¤ ìƒ‰ìƒ (ì´ìƒ íƒì§€ ì‹œ ë¹¨ê°„ìƒ‰, ì •ìƒ ì‹œ ë…¹ìƒ‰)
                color = (0, 0, 255) if is_anomaly else (0, 255, 0)
                thickness = 2 if is_anomaly else 1
                
                # ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                cv2.rectangle(overlay, (x1, y1), (x2, y2), color, thickness)
                
                # ë ˆì´ë¸” í…ìŠ¤íŠ¸
                label = f"{class_name} {conf:.2f}"
                if is_anomaly:
                    label += " âš ï¸ ì´ìƒ!"
                
                # í…ìŠ¤íŠ¸ ë°°ê²½
                (text_width, text_height), baseline = cv2.getTextSize(
                    label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1
                )
                cv2.rectangle(
                    overlay, 
                    (x1, y1 - text_height - 5), 
                    (x1 + text_width, y1), 
                    color, 
                    -1
                )
                
                # í…ìŠ¤íŠ¸ í‘œì‹œ
                cv2.putText(
                    overlay, 
                    label, 
                    (x1, y1 - 5), 
                    cv2.FONT_HERSHEY_SIMPLEX, 
                    0.5, 
                    (255, 255, 255), 
                    1
                )

        # AiVAD region ë°•ìŠ¤ëŠ” ë¹„í™œì„±í™” (ì´ìƒ íƒì§€ë§Œ í•˜ë¯€ë¡œ ë¶ˆí•„ìš”)
        # YOLO ê°ì²´ ê°ì§€ë§Œ ì‚¬ìš©í•˜ë©´ ë¨
        
        # ìƒë‹¨ì— ê°ì§€ëœ ê°ì²´ ëª©ë¡ í‘œì‹œ
        if detected_objects:
            unique_objects = list(set(detected_objects))
            objects_text = f"ê°ì§€ëœ ê°ì²´: {', '.join(unique_objects)}"
            if is_anomaly:
                objects_text += " âš ï¸ ì´ìƒ í–‰ë™!"
            
            # í…ìŠ¤íŠ¸ ë°°ê²½
            (text_width, text_height), baseline = cv2.getTextSize(
                objects_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
            )
            cv2.rectangle(
                overlay,
                (10, 10),
                (10 + text_width + 10, 10 + text_height + 10),
                (0, 0, 0),
                -1
            )
            
            # í…ìŠ¤íŠ¸ ìƒ‰ìƒ (ì´ìƒ ì‹œ ë¹¨ê°„ìƒ‰, ì •ìƒ ì‹œ í°ìƒ‰)
            text_color = (0, 0, 255) if is_anomaly else (255, 255, 255)
            cv2.putText(
                overlay,
                objects_text,
                (15, 10 + text_height),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                text_color,
                2
            )

        return overlay


class AnomalyLogger:
    """ì´ìƒìƒí™© ë¡œê·¸ ì €ì¥ í´ë˜ìŠ¤"""
    def __init__(self, log_dir: str = "anomaly_logs") -> None:
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        self.logs = []

    def log_anomaly(self, timestamp: str, anomaly_type: str, score: float, 
                   screenshot_path: str, frame_number: int = 0, 
                   location: Optional[Dict[str, Any]] = None) -> None:
        """ì´ìƒìƒí™© ë¡œê·¸ ì €ì¥"""
        log_entry = {
            "timestamp": timestamp,
            "anomaly_type": anomaly_type,
            "score": float(score),
            "screenshot_path": screenshot_path,
            "screenshot_location": location if location else {},
            "frame_number": frame_number,
        }
        self.logs.append(log_entry)

    def save_screenshot(self, frame: np.ndarray, timestamp: str) -> str:
        """ìŠ¤í¬ë¦°ìƒ· ì €ì¥"""
        timestamp_clean = timestamp.replace(":", "-").replace(".", "-")
        screenshot_path = self.log_dir / f"screenshot_{timestamp_clean}.jpg"
        cv2.imwrite(str(screenshot_path), frame)
        return str(screenshot_path)

    def save_logs(self) -> None:
        """ë¡œê·¸ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        if not self.logs:
            return
        
        log_file = self.log_dir / "anomaly_logs.json"
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(self.logs, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ë¡œê·¸ ì €ì¥ ì™„ë£Œ: {log_file} ({len(self.logs)}ê°œ í•­ëª©)")


class MainWindow(QtWidgets.QMainWindow):
    """ë©”ì¸ ìœˆë„ìš°"""
    def __init__(self) -> None:
        super().__init__()
        self.setWindowTitle("AiVAD ë°ëª¨ UI - ì‹¤ì‹œê°„ ì´ìƒ íƒì§€")
        self.resize(1400, 900)

        # ìƒíƒœ
        self.video_path: Optional[str] = None
        self.threshold: float = 0.5
        self.is_anomaly_detected = False
        self.frame_number = 0
        self.last_anomaly_frame = -1  # ë§ˆì§€ë§‰ ì´ìƒ íƒì§€ í”„ë ˆì„ ë²ˆí˜¸

        # ëª¨ë¸ ë° ë¡œê±° ì´ˆê¸°í™” (í”„ë ˆì„ ìŠ¤í‚µ: 15í”„ë ˆì„ë§ˆë‹¤ í•œ ë²ˆë§Œ ì¶”ë¡  - ì‹¤ì‹œê°„ ì„±ëŠ¥ ìµœì í™”)
        self.inferencer = AiVadInferencer(device="cuda", skip_frames=15)  # 15í”„ë ˆì„ë§ˆë‹¤ ì¶”ë¡  (ìµœëŒ€ ì„±ëŠ¥)
        self.logger = AnomalyLogger()

        # UI êµ¬ì„±
        self._setup_ui()
        self._connect_signals()

        # ìŠ¤ë ˆë“œ
        self.reader: Optional[VideoReaderThread] = None

        # ë¹¨ê°„ í…Œë‘ë¦¬ íƒ€ì´ë¨¸ ì´ˆê¸°í™”
        self.border_timer = QtCore.QTimer()
        self.border_timer.setSingleShot(True)
        self.border_timer.timeout.connect(self._remove_anomaly_border)

    def _setup_ui(self) -> None:
        """UI êµ¬ì„±"""
        central = QtWidgets.QWidget(self)
        self.setCentralWidget(central)
        layout = QtWidgets.QVBoxLayout(central)

        # ìƒë‹¨ ì»¨íŠ¸ë¡¤ ë°”
        controls = QtWidgets.QHBoxLayout()
        
        # ë¹„ë””ì˜¤ ì„ íƒ
        video_group = QtWidgets.QGroupBox("ë¹„ë””ì˜¤ ì„ íƒ")
        video_layout = QtWidgets.QVBoxLayout()
        self.btn_select_video = QtWidgets.QPushButton("ğŸ“ ë¹„ë””ì˜¤ íŒŒì¼ ì„ íƒ")
        self.btn_select_video.setMinimumHeight(40)
        self.lbl_video_path = QtWidgets.QLabel("ì„ íƒëœ ë¹„ë””ì˜¤: ì—†ìŒ")
        self.lbl_video_path.setWordWrap(True)
        video_layout.addWidget(self.btn_select_video)
        video_layout.addWidget(self.lbl_video_path)
        video_group.setLayout(video_layout)
        controls.addWidget(video_group)

        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        model_group = QtWidgets.QGroupBox("ëª¨ë¸")
        model_layout = QtWidgets.QVBoxLayout()
        self.btn_load_checkpoint = QtWidgets.QPushButton("âš™ï¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ")
        self.lbl_checkpoint = QtWidgets.QLabel("ì²´í¬í¬ì¸íŠ¸: ê¸°ë³¸ ëª¨ë¸")
        self.lbl_checkpoint.setWordWrap(True)
        model_layout.addWidget(self.btn_load_checkpoint)
        model_layout.addWidget(self.lbl_checkpoint)
        model_group.setLayout(model_layout)
        controls.addWidget(model_group)

        # ì¬ìƒ ì»¨íŠ¸ë¡¤
        play_group = QtWidgets.QGroupBox("ì¬ìƒ ì»¨íŠ¸ë¡¤")
        play_layout = QtWidgets.QHBoxLayout()
        self.btn_play = QtWidgets.QPushButton("â–¶ ì¬ìƒ")
        self.btn_pause = QtWidgets.QPushButton("â¸ ì¼ì‹œì •ì§€")
        self.btn_stop = QtWidgets.QPushButton("â¹ ì •ì§€")
        play_layout.addWidget(self.btn_play)
        play_layout.addWidget(self.btn_pause)
        play_layout.addWidget(self.btn_stop)
        play_group.setLayout(play_layout)
        controls.addWidget(play_group)

        # ì„ê³„ì¹˜ ì„¤ì •
        threshold_group = QtWidgets.QGroupBox("ì„ê³„ì¹˜ ì„¤ì •")
        threshold_layout = QtWidgets.QVBoxLayout()
        self.threshold_slider = QtWidgets.QSlider(QtCore.Qt.Orientation.Horizontal)
        self.threshold_slider.setRange(10, 100)
        self.threshold_slider.setValue(int(self.threshold * 100))
        self.lbl_threshold = QtWidgets.QLabel(f"ì„ê³„ì¹˜: {self.threshold:.2f}")
        threshold_layout.addWidget(self.lbl_threshold)
        threshold_layout.addWidget(self.threshold_slider)
        threshold_group.setLayout(threshold_layout)
        controls.addWidget(threshold_group)

        # ì„±ëŠ¥ ìµœì í™” ì„¤ì •
        perf_group = QtWidgets.QGroupBox("ì„±ëŠ¥ ìµœì í™”")
        perf_layout = QtWidgets.QVBoxLayout()
        
        # í”„ë ˆì„ ìŠ¤í‚µ ì„¤ì •
        skip_layout = QtWidgets.QHBoxLayout()
        skip_layout.addWidget(QtWidgets.QLabel("í”„ë ˆì„ ìŠ¤í‚µ:"))
        self.skip_frames_spinbox = QtWidgets.QSpinBox()
        self.skip_frames_spinbox.setRange(1, 30)  # ë²”ìœ„ í™•ëŒ€ (ìµœëŒ€ 30í”„ë ˆì„ë§ˆë‹¤)
        self.skip_frames_spinbox.setValue(15)  # ê¸°ë³¸ê°’ 15í”„ë ˆì„ë§ˆë‹¤ ì¶”ë¡  (ì‹¤ì‹œê°„ ìµœì í™”)
        self.skip_frames_spinbox.setToolTip("N í”„ë ˆì„ë§ˆë‹¤ í•œ ë²ˆë§Œ ì¶”ë¡  (ë†’ì„ìˆ˜ë¡ ë¹ ë¦„, ë‚®ì„ìˆ˜ë¡ ì •í™•)")
        skip_layout.addWidget(self.skip_frames_spinbox)
        skip_layout.addWidget(QtWidgets.QLabel("í”„ë ˆì„ë§ˆë‹¤"))
        perf_layout.addLayout(skip_layout)
        
        perf_group.setLayout(perf_layout)
        controls.addWidget(perf_group)

        # ì‹œê°í™” ì„¤ì •
        viz_group = QtWidgets.QGroupBox("ì‹œê°í™” ì„¤ì •")
        viz_layout = QtWidgets.QVBoxLayout()
        
        # YOLO ê°ì²´ ê°ì§€ ì˜µì…˜
        self.use_yolo_cb = QtWidgets.QCheckBox("YOLO ê°ì²´ ê°ì§€ (ë¬´ì—‡ì´ ìˆëŠ”ì§€ í‘œì‹œ)")
        self.use_yolo_cb.setChecked(True)  # ê¸°ë³¸ê°’: í™œì„±í™”
        self.use_yolo_cb.setToolTip("ì²´í¬í•˜ë©´ YOLOë¡œ ê°ì²´(ì‚¬ëŒ, ì°¨ëŸ‰ ë“±)ë¥¼ ê°ì§€í•˜ì—¬ í‘œì‹œí•©ë‹ˆë‹¤")
        viz_layout.addWidget(self.use_yolo_cb)
        
        # íˆíŠ¸ë§µ í‘œì‹œ ì˜µì…˜
        self.show_heatmap_cb = QtWidgets.QCheckBox("íˆíŠ¸ë§µ í‘œì‹œ (ê¸°ë¦„ í•„í„° íš¨ê³¼)")
        self.show_heatmap_cb.setChecked(False)  # ê¸°ë³¸ê°’: ë¹„í™œì„±í™”
        self.show_heatmap_cb.setToolTip("ì²´í¬í•˜ë©´ ì´ìƒ ì˜ì—­ì— ì»¬ëŸ¬ ë§µ ì˜¤ë²„ë ˆì´ê°€ í‘œì‹œë©ë‹ˆë‹¤")
        viz_layout.addWidget(self.show_heatmap_cb)
        
        # íˆíŠ¸ë§µ íˆ¬ëª…ë„
        heatmap_alpha_layout = QtWidgets.QHBoxLayout()
        heatmap_alpha_layout.addWidget(QtWidgets.QLabel("íˆíŠ¸ë§µ íˆ¬ëª…ë„:"))
        self.heatmap_alpha_slider = QtWidgets.QSlider(QtCore.Qt.Orientation.Horizontal)
        self.heatmap_alpha_slider.setRange(10, 90)
        self.heatmap_alpha_slider.setValue(30)
        self.heatmap_alpha_slider.setToolTip("íˆíŠ¸ë§µ íˆ¬ëª…ë„ (10-90%)")
        heatmap_alpha_layout.addWidget(self.heatmap_alpha_slider)
        viz_layout.addLayout(heatmap_alpha_layout)
        
        viz_group.setLayout(viz_layout)
        controls.addWidget(viz_group)

        layout.addLayout(controls)

        # ë¹„ë””ì˜¤ í‘œì‹œ ì˜ì—­
        self.video_label = QtWidgets.QLabel()
        self.video_label.setAlignment(QtCore.Qt.AlignmentFlag.AlignCenter)
        self.video_label.setText("ë¹„ë””ì˜¤ë¥¼ ì„ íƒí•˜ê³  ì¬ìƒ ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”")
        self.video_label.setStyleSheet("""
            QLabel {
                background-color: #111111; 
                color: white; 
                border: 2px solid #333333;
                font-size: 16px;
            }
        """)
        layout.addWidget(self.video_label, stretch=1)

        # í•˜ë‹¨ ìƒíƒœ ë°”
        status_layout = QtWidgets.QHBoxLayout()
        self.lbl_status = QtWidgets.QLabel("ìƒíƒœ: ëŒ€ê¸°")
        self.lbl_score = QtWidgets.QLabel("ì ìˆ˜: 0.000")
        self.lbl_anomaly = QtWidgets.QLabel("ì •ìƒ")
        self.lbl_anomaly.setStyleSheet("color: #00ff00; font-weight: bold; font-size: 14px;")
        self.lbl_frame = QtWidgets.QLabel("í”„ë ˆì„: 0")
        self.lbl_log_count = QtWidgets.QLabel("ë¡œê·¸: 0ê°œ")
        
        status_layout.addWidget(self.lbl_status)
        status_layout.addWidget(self.lbl_score)
        status_layout.addWidget(self.lbl_anomaly)
        status_layout.addWidget(self.lbl_frame)
        status_layout.addWidget(self.lbl_log_count)
        layout.addLayout(status_layout)

    def _connect_signals(self) -> None:
        """ì‹œê·¸ë„ ì—°ê²°"""
        self.btn_select_video.clicked.connect(self.on_select_video)
        self.btn_load_checkpoint.clicked.connect(self.on_load_checkpoint)
        self.btn_play.clicked.connect(self.on_play)
        self.btn_pause.clicked.connect(self.on_pause)
        self.btn_stop.clicked.connect(self.on_stop)
        self.threshold_slider.valueChanged.connect(self.on_threshold_changed)
        self.skip_frames_spinbox.valueChanged.connect(self.on_skip_frames_changed)
        self.use_yolo_cb.toggled.connect(self.on_use_yolo_toggled)
        self.show_heatmap_cb.toggled.connect(self.on_show_heatmap_toggled)
        self.heatmap_alpha_slider.valueChanged.connect(self.on_heatmap_alpha_changed)

    def on_threshold_changed(self, value: int) -> None:
        """ì„ê³„ì¹˜ ë³€ê²½"""
        self.threshold = float(value) / 100.0
        self.lbl_threshold.setText(f"ì„ê³„ì¹˜: {self.threshold:.2f}")
    
    def on_skip_frames_changed(self, value: int) -> None:
        """í”„ë ˆì„ ìŠ¤í‚µ ë³€ê²½"""
        self.inferencer.skip_frames = value
        self.inferencer.frame_counter = 0  # ë¦¬ì…‹
        self.status_message(f"í”„ë ˆì„ ìŠ¤í‚µ: {value}í”„ë ˆì„ë§ˆë‹¤ ì¶”ë¡ ")
    
    def on_use_yolo_toggled(self, checked: bool) -> None:
        """YOLO ì‚¬ìš© í† ê¸€"""
        self.inferencer.use_yolo = checked
        if checked and self.inferencer.yolo_model is None:
            self.inferencer._init_yolo()
        self.status_message("YOLO ê°ì²´ ê°ì§€: " + ("ì¼œì§" if checked else "êº¼ì§"))
    
    def on_show_heatmap_toggled(self, checked: bool) -> None:
        """íˆíŠ¸ë§µ í‘œì‹œ í† ê¸€"""
        self.inferencer.show_heatmap = checked
        self.status_message("íˆíŠ¸ë§µ í‘œì‹œ: " + ("ì¼œì§" if checked else "êº¼ì§"))
    
    def on_heatmap_alpha_changed(self, value: int) -> None:
        """íˆíŠ¸ë§µ íˆ¬ëª…ë„ ë³€ê²½"""
        self.inferencer.heatmap_alpha = float(value) / 100.0

    def on_select_video(self) -> None:
        """ë¹„ë””ì˜¤ íŒŒì¼ ì„ íƒ"""
        path, _ = QtWidgets.QFileDialog.getOpenFileName(
            self, "ë¹„ë””ì˜¤ íŒŒì¼ ì„ íƒ", os.getcwd(), 
            "Video Files (*.mp4 *.avi *.mov *.mkv *.flv *.wmv);;All Files (*)"
        )
        if path:
            self.video_path = path
            filename = os.path.basename(path)
            self.lbl_video_path.setText(f"ì„ íƒëœ ë¹„ë””ì˜¤: {filename}")
            self.status_message(f"ë¹„ë””ì˜¤ ì„ íƒ: {filename}")
            self.inferencer.frame_buffer.clear()
            self.inferencer.frame_counter = 0  # í”„ë ˆì„ ì¹´ìš´í„° ë¦¬ì…‹
            self.inferencer.yolo_frame_counter = 0  # YOLO í”„ë ˆì„ ì¹´ìš´í„° ë¦¬ì…‹
            self.frame_number = 0
            self.last_anomaly_frame = -1

    def on_load_checkpoint(self) -> None:
        """ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
        path, _ = QtWidgets.QFileDialog.getOpenFileName(
            self, "ì²´í¬í¬ì¸íŠ¸ ì„ íƒ", os.getcwd(), 
            "Checkpoint (*.ckpt *.pt *.pth);;All Files (*)"
        )
        if path:
            try:
                self.inferencer.load_checkpoint(path)
                filename = os.path.basename(path)
                self.lbl_checkpoint.setText(f"ì²´í¬í¬ì¸íŠ¸: {filename}")
                self.status_message(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì™„ë£Œ: {filename}")
            except Exception as e:
                QtWidgets.QMessageBox.critical(self, "ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨", str(e))

    def on_play(self) -> None:
        """ì¬ìƒ ì‹œì‘"""
        if not self.video_path:
            QtWidgets.QMessageBox.information(self, "ì•ˆë‚´", "ë¨¼ì € ë¹„ë””ì˜¤ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.")
            return
            
        if self.reader and self.reader.isRunning():
            self.reader.pause(False)
            self.status_message("ì¬ìƒ")
            return

        self.reader = VideoReaderThread(self.video_path, fps_limit=8.0)  # FPS ì œí•œ (ë” ëŠë¦¬ê²Œ - ì‹¤ì‹œê°„ ìµœì í™”)
        self.reader.frameReady.connect(self.on_frame)
        self.reader.finished.connect(self.on_reader_finished)
        self.reader.start()
        self.status_message("ì¬ìƒ ì‹œì‘")

    def on_pause(self) -> None:
        """ì¼ì‹œì •ì§€"""
        if self.reader and self.reader.isRunning():
            self.reader.pause(True)
            self.status_message("ì¼ì‹œì •ì§€")

    def on_stop(self) -> None:
        """ì •ì§€"""
        if self.reader:
            self.reader.stop()
            self.reader.wait(1000)
            self.reader = None
        self.status_message("ì •ì§€")
        # ë¡œê·¸ ì €ì¥
        self.logger.save_logs()

    @QtCore.Slot(np.ndarray)
    def on_frame(self, frame_bgr: np.ndarray) -> None:
        """í”„ë ˆì„ ì²˜ë¦¬"""
        try:
            overlay, score, info = self.inferencer.infer_on_frame(frame_bgr)
            self.frame_number += 1
        except Exception as e:
            print(f"âš ï¸ ì¶”ë¡  ì˜¤ë¥˜: {e}")
            overlay = frame_bgr
            score = 0.0
            info = {"anomaly_type": "ì •ìƒ"}

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        self.lbl_score.setText(f"ì ìˆ˜: {score:.3f}")
        self.lbl_frame.setText(f"í”„ë ˆì„: {self.frame_number}")
        self.lbl_log_count.setText(f"ë¡œê·¸: {len(self.logger.logs)}ê°œ")

        # ì´ìƒ íƒì§€ ì—¬ë¶€ í™•ì¸
        is_anomaly = score >= self.threshold
        
        if is_anomaly:
            self.lbl_anomaly.setText(f"âš ï¸ ì´ìƒ íƒì§€: {info.get('anomaly_type', 'ì´ìƒ')}")
            self.lbl_anomaly.setStyleSheet("color: #ff0000; font-weight: bold; font-size: 14px;")
            
            # ì´ì „ì— ì´ìƒì´ ê°ì§€ë˜ì§€ ì•Šì•˜ì„ ë•Œë§Œ ì²˜ë¦¬ (ìƒˆë¡œìš´ ì´ìƒ íƒì§€)
            was_anomaly_before = self.is_anomaly_detected
            if not was_anomaly_before:
                self._handle_anomaly_detection(frame_bgr, score, info)
            
            self.is_anomaly_detected = True
        else:
            self.lbl_anomaly.setText("ì •ìƒ")
            self.lbl_anomaly.setStyleSheet("color: #00ff00; font-weight: bold; font-size: 14px;")
            self.is_anomaly_detected = False

        # í”„ë ˆì„ í‘œì‹œ
        self._display_frame(overlay, is_anomaly)

    def _handle_anomaly_detection(self, frame: np.ndarray, score: float, info: Dict[str, Any]) -> None:
        """ì´ìƒ íƒì§€ ì²˜ë¦¬"""
        # ì—°ì† í”„ë ˆì„ì—ì„œ ì¤‘ë³µ ë°©ì§€ (ìµœì†Œ 30í”„ë ˆì„ ê°„ê²©)
        if self.frame_number - self.last_anomaly_frame < 30:
            return
        
        self.last_anomaly_frame = self.frame_number
        
        # 1. íŒì—… ì•Œë¦¼
        anomaly_type = info.get("anomaly_type", "ì´ìƒ")
        msg = QtWidgets.QMessageBox(self)
        msg.setIcon(QtWidgets.QMessageBox.Icon.Warning)
        msg.setWindowTitle("âš ï¸ ì´ìƒìƒí™© íƒì§€")
        msg.setText(f"ì´ìƒìƒí™©ì´ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤!")
        msg.setInformativeText(f"ìœ í˜•: {anomaly_type}\nì ìˆ˜: {score:.3f}\ní”„ë ˆì„: {self.frame_number}")
        msg.setStandardButtons(QtWidgets.QMessageBox.StandardButton.Ok)
        msg.exec()

        # 2. ë¡œê·¸ ì €ì¥
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]
        screenshot_path = self.logger.save_screenshot(frame, timestamp)
        
        # ì´ìƒ íƒì§€ ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ
        location = {}
        regions = info.get("regions")
        if regions is not None and len(regions) > 0:
            region = regions[0]
            if 'boxes' in region:
                boxes = region['boxes'].detach().cpu().numpy()
                location["boxes"] = boxes.tolist()
            if 'masks' in region:
                # ë§ˆìŠ¤í¬ëŠ” ë„ˆë¬´ ì»¤ì„œ ë¡œê·¸ì—ëŠ” í¬í•¨í•˜ì§€ ì•ŠìŒ
                location["has_masks"] = True
        
        self.logger.log_anomaly(
            timestamp=timestamp,
            anomaly_type=anomaly_type,
            score=score,
            screenshot_path=screenshot_path,
            frame_number=self.frame_number,
            location=location
        )

        # 3. ë¹¨ê°„ í…Œë‘ë¦¬ í‘œì‹œ (1ì´ˆê°„)
        self._show_anomaly_border()

    def _show_anomaly_border(self) -> None:
        """ë¹¨ê°„ í…Œë‘ë¦¬ í‘œì‹œ"""
        # íƒ€ì´ë¨¸ê°€ ì‹¤í–‰ ì¤‘ì´ë©´ ì¤‘ì§€
        if self.border_timer.isActive():
            self.border_timer.stop()
        
        # ë¹¨ê°„ í…Œë‘ë¦¬ ì ìš©
        self.video_label.setStyleSheet("""
            QLabel {
                background-color: #111111; 
                color: white; 
                border: 5px solid #ff0000;
                font-size: 16px;
            }
        """)
        # 1ì´ˆ í›„ ì œê±°
        self.border_timer.start(1000)  # 1000ms = 1ì´ˆ

    def _remove_anomaly_border(self) -> None:
        """ë¹¨ê°„ í…Œë‘ë¦¬ ì œê±°"""
        self.video_label.setStyleSheet("""
            QLabel {
                background-color: #111111; 
                color: white; 
                border: 2px solid #333333;
                font-size: 16px;
            }
        """)

    def _display_frame(self, frame_bgr: np.ndarray, is_anomaly: bool = False) -> None:
        """í”„ë ˆì„ í‘œì‹œ"""
        h, w = frame_bgr.shape[:2]
        rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
        qimg = QtGui.QImage(rgb.data, w, h, 3 * w, QtGui.QImage.Format.Format_RGB888)
        pixmap = QtGui.QPixmap.fromImage(qimg)
        pixmap = pixmap.scaled(
            self.video_label.size(), 
            QtCore.Qt.AspectRatioMode.KeepAspectRatio, 
            QtCore.Qt.TransformationMode.SmoothTransformation
        )
        self.video_label.setPixmap(pixmap)

    def resizeEvent(self, event: QtGui.QResizeEvent) -> None:
        """ë¦¬ì‚¬ì´ì¦ˆ ì´ë²¤íŠ¸"""
        if self.video_label.pixmap():
            self.video_label.setPixmap(
                self.video_label.pixmap().scaled(
                    self.video_label.size(), 
                    QtCore.Qt.AspectRatioMode.KeepAspectRatio, 
                    QtCore.Qt.TransformationMode.SmoothTransformation
                )
            )
        super().resizeEvent(event)

    def closeEvent(self, event: QtGui.QCloseEvent) -> None:
        """ì¢…ë£Œ ì´ë²¤íŠ¸"""
        if self.reader:
            self.reader.stop()
            self.reader.wait(1000)
        # ë¡œê·¸ ì €ì¥
        self.logger.save_logs()
        super().closeEvent(event)

    def on_reader_finished(self) -> None:
        """ì½ê¸° ì™„ë£Œ"""
        self.status_message("ì˜ìƒ ì¢…ë£Œ")
        # ë¡œê·¸ ì €ì¥
        self.logger.save_logs()

    def status_message(self, msg: str) -> None:
        """ìƒíƒœ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸"""
        self.lbl_status.setText(f"ìƒíƒœ: {msg}")


def main() -> None:
    """ë©”ì¸ í•¨ìˆ˜"""
    app = QtWidgets.QApplication(sys.argv)
    w = MainWindow()
    w.show()
    sys.exit(app.exec())


if __name__ == "__main__":
    main()

