"""
AI-VAD ì˜¬ë°”ë¥¸ í•™ìŠµ ë°©ë²• (ìµœì¢… ì •ì • ë²„ì „)
AI-VAD ì›ë˜ ë°©ì‹ê³¼ ë™ì¼í•˜ê²Œ ë™ì‘í•˜ë„ë¡ ìˆ˜ì •
"""

import os
import json
import torch
import cv2
import numpy as np
from pathlib import Path
from anomalib.models.video import AiVad
from anomalib.engine import Engine
from anomalib.data import Folder
import shutil
from torch.utils.data import Dataset, DataLoader

class CorrectVideoDataset(Dataset):
    """AI-VAD ì›ë˜ ë°©ì‹ê³¼ ë™ì¼í•œ ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ ë°ì´í„°ì…‹"""
    
    def __init__(self, image_folder, sequence_length=2, transform=None):
        self.image_folder = Path(image_folder)
        self.sequence_length = sequence_length
        self.transform = transform
        
        # ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜ì§‘
        self.image_files = sorted([f for f in self.image_folder.glob("*.jpg")])
        print(f"ğŸ“¸ ì´ {len(self.image_files)}ê°œ ì´ë¯¸ì§€ ë°œê²¬")
        
        # ì‹œí€€ìŠ¤ ìƒì„± (ì—°ì†ëœ í”„ë ˆì„ë“¤)
        self.sequences = []
        for i in range(len(self.image_files) - sequence_length + 1):
            sequence = self.image_files[i:i + sequence_length]
            self.sequences.append(sequence)
        
        print(f"ğŸ¬ {len(self.sequences)}ê°œ ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ ìƒì„±")
    
    def __len__(self):
        return len(self.sequences)
    
    def __getitem__(self, idx):
        sequence_paths = self.sequences[idx]
        frames = []
        
        # ê° ì‹œí€€ìŠ¤ì—ì„œ í”„ë ˆì„ ë¡œë“œ
        for path in sequence_paths:
            frame = cv2.imread(str(path))
            if frame is None:
                # ë¹ˆ í”„ë ˆì„ ìƒì„±
                frame = np.zeros((224, 224, 3), dtype=np.uint8)
            else:
                # 224x224ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                frame = cv2.resize(frame, (224, 224))
            
            # BGR to RGB
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # ì •ê·œí™” [0, 1]
            frame = frame.astype(np.float32) / 255.0
            
            # CHW í˜•íƒœë¡œ ë³€í™˜
            frame = np.transpose(frame, (2, 0, 1))
            frames.append(frame)
        
        # í…ì„œë¡œ ë³€í™˜ [sequence_length, 3, 224, 224]
        video_tensor = torch.from_numpy(np.array(frames))
        
        # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ [1, sequence_length, 3, 224, 224]
        video_tensor = video_tensor.unsqueeze(0)
        
        return {
            'image': video_tensor,
            'label': torch.tensor(0),  # ì •ìƒ ë°ì´í„°
            'image_path': str(sequence_paths[0])  # ì²« ë²ˆì§¸ í”„ë ˆì„ ê²½ë¡œ
        }

def create_correct_dataset_from_json(json_path="image_segments.json", target_dir="correct_dataset"):
    """JSONì—ì„œ ì •ìƒ í”„ë ˆì„ë“¤ì„ ì˜¬ë°”ë¥¸ ë°ì´í„°ì…‹ìœ¼ë¡œ ë³€í™˜"""
    print(f"ğŸ“ AI-VADìš© ì˜¬ë°”ë¥¸ ë°ì´í„°ì…‹ ìƒì„±: {json_path}")
    
    # í´ë” ìƒì„±
    normal_dir = Path(target_dir) / "train" / "good"
    normal_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"  ğŸ“‚ ì •ìƒ ì´ë¯¸ì§€ í´ë”: {normal_dir}")
    
    # JSON íŒŒì¼ ë¡œë“œ
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            segments = json.load(f)
        print(f"  ğŸ“Š JSON ë¡œë“œ ì™„ë£Œ: {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
    except Exception as e:
        print(f"âŒ JSON ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None
    
    # ì •ìƒ í”„ë ˆì„ë“¤ ì¶”ì¶œ
    copied_count = 0
    normal_count = 0
    
    for i, segment in enumerate(segments):
        if segment.get('category') == 'normal' and 'images' in segment:
            normal_count += 1
            images = segment['images']
            
            # ê° ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ í”„ë ˆì„ë“¤ ë³µì‚¬
            for j, img_path in enumerate(images[:5]):  # ê° ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ìµœëŒ€ 5ê°œ
                if os.path.exists(img_path):
                    # íŒŒì¼ëª… ìƒì„±
                    name = f"normal_{normal_count:03d}_{j:02d}_{Path(img_path).name}"
                    target_path = normal_dir / name
                    
                    try:
                        # íŒŒì¼ ë³µì‚¬
                        shutil.copy2(img_path, target_path)
                        copied_count += 1
                        
                        if copied_count <= 20:  # ì²˜ìŒ 20ê°œë§Œ í‘œì‹œ
                            print(f"    ğŸ“¸ {name}")
                            
                    except Exception as e:
                        print(f"    âš ï¸ {img_path} ë³µì‚¬ ì‹¤íŒ¨: {e}")
    
    print(f"  âœ… ì •ìƒ ì„¸ê·¸ë¨¼íŠ¸: {normal_count}ê°œ")
    print(f"  âœ… ë³µì‚¬ëœ ì´ë¯¸ì§€: {copied_count}ê°œ")
    
    if copied_count == 0:
        print("âŒ ë³µì‚¬ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return None
    
    return str(Path(target_dir).absolute())

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ AI-VAD ì˜¬ë°”ë¥¸ í•™ìŠµ ë°©ë²• (ìµœì¢… ì •ì • ë²„ì „)")
    print("=" * 60)
    print("ğŸ’¡ AI-VAD ì›ë˜ ë°©ì‹:")
    print("   1. Feature Extraction: Flow, Region, Pose, Deep features")
    print("   2. Density Estimation: ì •ìƒ ë°ì´í„°ì˜ ë¶„í¬ í•™ìŠµ")
    print("   3. One-Class Learning: ì •ìƒ ë°ì´í„°ë§Œìœ¼ë¡œ ë¶„í¬ ëª¨ë¸ë§")
    print("   4. No NN Training: ê°€ì¤‘ì¹˜ í•™ìŠµ ì—†ìŒ!")
    print("   5. ìš°ë¦¬ ë°ì´í„° ì‚¬ìš©: Domain ì ìš©ì„± í–¥ìƒ")
    print("=" * 60)
    
    # GPU ì„¤ì •
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ–¥ï¸ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    if device == "cuda":
        print(f"GPU: {torch.cuda.get_device_name()}")
    
    # 1. ì˜¬ë°”ë¥¸ ë°ì´í„°ì…‹ ìƒì„±
    dataset_root = create_correct_dataset_from_json()
    if dataset_root is None:
        print("âŒ ì˜¬ë°”ë¥¸ ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨")
        return
    
    # 2. AI-VAD ëª¨ë¸ ìƒì„± (ì›ë˜ ì„¤ì •)
    print(f"\nğŸ¤– AI-VAD ëª¨ë¸ ìƒì„±...")
    try:
        model = AiVad(
            # AI-VAD ì›ë˜ ì„¤ì • (ëª¨ë“  Feature í™œì„±í™”)
            use_velocity_features=True,
            use_pose_features=True,
            use_deep_features=True,
            # Density estimation ì„¤ì •
            n_components_velocity=2,
            n_neighbors_pose=1,
            n_neighbors_deep=1,
        )
        print("âœ… AI-VAD ëª¨ë¸ ìƒì„± ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ AI-VAD ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return
    
    # 3. ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
    checkpoint_path = "aivad_proper_checkpoint.ckpt"
    if os.path.exists(checkpoint_path):
        print(f"\nğŸ”„ ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ: {checkpoint_path}")
        try:
            checkpoint = torch.load(checkpoint_path, weights_only=False)
            if 'state_dict' in checkpoint:
                model.load_state_dict(checkpoint['state_dict'], strict=False)
                print("âœ… ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ")
            else:
                print("âš ï¸ state_dictê°€ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # 4. Anomalib Engine ìƒì„± (AI-VAD ì „ìš© ì„¤ì •)
    print(f"\nğŸ”§ Anomalib Engine ìƒì„±...")
    try:
        engine = Engine(
            devices=1 if device == "cuda" else "auto",
            accelerator="gpu" if device == "cuda" else "cpu",
            precision="32",  # AI-VADëŠ” 32bit ì‚¬ìš©
            # AI-VAD ì „ìš© ì„¤ì •
            max_epochs=1,  # AI-VADëŠ” 1 ì—í¬í¬ë§Œ
            gradient_clip_val=0,  # Gradient clipping ì—†ìŒ
            log_every_n_steps=1,
            enable_progress_bar=True,
            enable_model_summary=False,  # ëª¨ë¸ ìš”ì•½ ë¹„í™œì„±í™”
            num_sanity_val_steps=0,  # ê²€ì¦ ë‹¨ê³„ ì—†ìŒ
        )
        
        print("âœ… Engine ìƒì„± ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ Engine ìƒì„± ì‹¤íŒ¨: {e}")
        return
    
    # 5. ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ ë°ì´í„°ì…‹ ìƒì„±
    print(f"\nğŸ“Š ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ ë°ì´í„°ì…‹ ìƒì„±...")
    try:
        normal_dir = Path(dataset_root) / "train" / "good"
        video_dataset = CorrectVideoDataset(normal_dir, sequence_length=2)
        
        # DataLoader ìƒì„±
        dataloader = DataLoader(
            video_dataset,
            batch_size=1,  # ì‘ì€ ë°°ì¹˜ í¬ê¸°
            shuffle=True,
            num_workers=0,
            drop_last=True
        )
        
        print(f"âœ… ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ")
        print(f"   ğŸ“Š ë°°ì¹˜ í¬ê¸°: {dataloader.batch_size}")
        print(f"   ğŸ“Š ì´ ë°°ì¹˜ ìˆ˜: {len(dataloader)}")
        
    except Exception as e:
        print(f"âŒ ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨: {e}")
        return
    
    # 6. AI-VAD í•™ìŠµ (ì›ë˜ ë°©ì‹)
    print(f"\nğŸ¯ AI-VAD í•™ìŠµ ì‹œì‘ (ì›ë˜ ë°©ì‹)...")
    print("ğŸ’¡ í•™ìŠµ ê³¼ì •:")
    print("   1. ì´ë¯¸ì§€ â†’ ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ ë³€í™˜")
    print("   2. Feature Extraction: Flow, Region, Pose, Deep features")
    print("   3. Density Update: ì •ìƒ íŠ¹ì„±ë“¤ì„ density estimatorì— ëˆ„ì ")
    print("   4. Density Fit: ëª¨ë“  íŠ¹ì„±ìœ¼ë¡œ ë¶„í¬ ëª¨ë¸ í•™ìŠµ")
    print("   5. No Backpropagation: ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ ì—†ìŒ!")
    print("   6. ìš°ë¦¬ ë°ì´í„° ì‚¬ìš©: Domain ì ìš©ì„± í–¥ìƒ!")
    
    try:
        # AI-VADì˜ ì˜¬ë°”ë¥¸ í•™ìŠµ ë°©ë²• (ì›ë˜ ë°©ì‹)
        model.eval().to(device)
        
        total_detections = 0
        successful_batches = 0
        
        for batch_idx, batch in enumerate(dataloader):
            try:
                # ë°ì´í„°ë¥¼ GPUë¡œ ì´ë™
                video_tensor = batch['image'].to(device)  # [batch_size, 1, 2, 3, 224, 224]
                
                # ë°°ì¹˜ ì°¨ì› ì¡°ì • [batch_size, 2, 3, 224, 224]
                video_tensor = video_tensor.squeeze(1)
                
                # AI-VAD ëª¨ë¸ í˜¸ì¶œ (ì›ë˜ ë°©ì‹)
                with torch.no_grad():
                    # AI-VADì˜ ì›ë˜ í•™ìŠµ ë°©ì‹
                    features_per_batch = model.model(video_tensor)
                
                # Density estimator ì—…ë°ì´íŠ¸ (ì›ë˜ ë°©ì‹)
                if hasattr(model.model, 'density_estimator'):
                    for features in features_per_batch:
                        model.model.density_estimator.update(features, f"video_{batch_idx}")
                        if features:
                            total_detections += len(next(iter(features.values())))
                
                successful_batches += 1
                
                if batch_idx % 10 == 0:
                    print(f"  ì²˜ë¦¬ëœ ë°°ì¹˜: {batch_idx + 1}/{len(dataloader)}")
                
            except Exception as e:
                print(f"  âš ï¸ ë°°ì¹˜ {batch_idx + 1} ì‹¤íŒ¨: {e}")
                # ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰
                continue
        
        print("âœ… AI-VAD í•™ìŠµ ì™„ë£Œ!")
        
        # Density estimator ìƒíƒœ í™•ì¸
        print(f"ğŸ“Š Density Estimator ìƒíƒœ:")
        print(f"   - ì„±ê³µí•œ ë°°ì¹˜: {successful_batches}/{len(dataloader)}")
        print(f"   - ì´ ê°ì§€ ìˆ˜: {total_detections}")
        
        # Density estimator fit í˜¸ì¶œ
        if total_detections > 0:
            model.fit()  # density estimator í•™ìŠµ
            print("âœ… Density Estimator í•™ìŠµ ì™„ë£Œ")
        else:
            print("âš ï¸ ê°ì§€ëœ ì˜ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
            print("ğŸ’¡ ì´ëŠ” ì •ìƒì ì¸ í˜„ìƒì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ë³µì¡í•œ ê°ì²´ ê°ì§€)")
        
    except Exception as e:
        print(f"âŒ AI-VAD í•™ìŠµ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # 7. ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    checkpoint_path = "aivad_correct_learned.ckpt"
    try:
        # AI-VAD ëª¨ë¸ ìƒíƒœ ì €ì¥
        torch.save({
            'state_dict': model.state_dict(),
            'pytorch-lightning_version': '2.0.0',
            'model_class': 'AiVad',
            'training_type': 'correct_density_estimation',
            'total_detections': total_detections,
        }, checkpoint_path)
        
        print(f"ğŸ’¾ í•™ìŠµëœ ëª¨ë¸ ì €ì¥: {checkpoint_path}")
        print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {os.path.getsize(checkpoint_path) / (1024**2):.1f} MB")
        
    except Exception as e:
        print(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    print("\nğŸ‰ AI-VAD ì˜¬ë°”ë¥¸ í•™ìŠµ ì™„ë£Œ!")
    print("ğŸ’¡ í•™ìŠµëœ ë‚´ìš©:")
    print("1. ìš°ë¦¬ ë°ì´í„°ë¡œ Domain ì ìš©ì„± í–¥ìƒ")
    print("2. ì´ë¯¸ì§€ â†’ ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ ë³€í™˜")
    print("3. ì •ìƒ ë°ì´í„°ì˜ Feature ë¶„í¬ í•™ìŠµ")
    print("4. Density Estimatorë¡œ ì´ìƒ íƒì§€ ì¤€ë¹„")
    print("5. UIì—ì„œ 'aivad_correct_learned.ckpt' ë¡œë“œí•˜ì—¬ í…ŒìŠ¤íŠ¸")
    print("6. ë¹„ì •ìƒ ë°ì´í„°ëŠ” ë¶„í¬ì—ì„œ ë²—ì–´ë‚˜ ë†’ì€ ì ìˆ˜")

if __name__ == "__main__":
    main()
