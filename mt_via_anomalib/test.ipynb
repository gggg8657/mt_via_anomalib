{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8208f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ cuDNN 비활성화 및 환경 설정 완료\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# cuDNN 오류 해결을 위한 환경 설정\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
    "\n",
    "# cuDNN 설정 조정 - cuDNN을 완전히 비활성화\n",
    "torch.backends.cudnn.enabled = False  # 이것이 핵심!\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "\n",
    "# 텐서 연속성 보장을 위한 설정\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# GPU 메모리 정리\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "print(\"✅ cuDNN 비활성화 및 환경 설정 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb20e8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongjukim/miniforge3/envs/mt_p310/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from anomalib.models.video import AiVad\n",
    "from anomalib.data import Avenue\n",
    "from anomalib.data.datasets.base.video import VideoTargetFrame\n",
    "from anomalib.engine import Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9a73797",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize model and datamodule\n",
    "datamodule = Avenue(\n",
    "    clip_length_in_frames=2,\n",
    "    frames_between_clips=1,\n",
    "    target_frame=VideoTargetFrame.LAST\n",
    ")\n",
    "model = AiVad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83d624bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anomalib.data import UCSDped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fa0a8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = UCSDped(root=\"/data/DJ/datasets/ucsd\")\n",
    "datamodule.prepare_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ba0616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from anomalib.data import ShanghaiTech\n",
    "# datamodule = ShanghaiTech(root=\"/data/DJ/datasets/shanghai\")\n",
    "# datamodule.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fe532a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anomalib.data import Avenue\n",
    "datamodule = Avenue(root=\"/data/DJ/datasets/avenue\")\n",
    "datamodule.prepare_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21089ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avenue 데이터셋 재설정 (cuDNN 에러 방지를 위한 설정)\n",
    "datamodule = Avenue(\n",
    "    root=\"/data/DJ/datasets/avenue\",\n",
    "    clip_length_in_frames=2,\n",
    "    frames_between_clips=1,\n",
    "    target_frame=VideoTargetFrame.LAST,\n",
    "    num_workers=2,  # 워커 수 줄이기\n",
    ")\n",
    "\n",
    "# Engine 설정\n",
    "engine = Engine(\n",
    "    devices=1,  # 노트북 환경에서는 단일 GPU 사용\n",
    "    accelerator='gpu',\n",
    "    precision='32',  # 32-bit precision 사용 (cuDNN 호환성)\n",
    "    max_epochs=10,  # 테스트를 위해 1 에포크만 실행\n",
    "    limit_train_batches=5,  # 배치 수 제한 (메모리 사용량 감소)\n",
    "    limit_val_batches=2,\n",
    "    accumulate_grad_batches=1,  # 그래디언트 누적 비활성화\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de29c9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]/home/dongjukim/miniforge3/envs/mt_p310/lib/python3.10/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\n",
      "  warnings.warn(\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.24it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]/home/dongjukim/miniforge3/envs/mt_p310/lib/python3.10/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\n",
      "  warnings.warn(\n",
      "100%|██████████| 2/2 [00:00<00:00, 17.90it/s]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [4,5]\n",
      "/home/dongjukim/miniforge3/envs/mt_p310/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:183: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name           | Type          | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | pre_processor  | PreProcessor  | 0      | train\n",
      "1 | post_processor | PostProcessor | 0      | train\n",
      "2 | evaluator      | Evaluator     | 0      | train\n",
      "3 | model          | AiVadModel    | 260 M  | train\n",
      "---------------------------------------------------------\n",
      "259 M     Trainable params\n",
      "447 K     Non-trainable params\n",
      "260 M     Total params\n",
      "1,041.500 Total estimated model params size (MB)\n",
      "670       Modules in train mode\n",
      "227       Modules in eval mode\n",
      "/home/dongjukim/miniforge3/envs/mt_p310/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 227 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d5a4d07e8b47ebbad48e82a1c62f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a28fd81c40c24c769d08aaf806862499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The validation set does not contain any anomalous images. As a result, the adaptive threshold will take the value of the highest anomaly score observed in the normal validation images, which may lead to poor predictions. For a more reliable adaptive threshold computation, please add some anomalous images to the validation set.\n",
      "/home/dongjukim/miniforge3/envs/mt_p310/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples found in target, recall is undefined. Setting recall to one for all thresholds.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "WARNING:root:The validation set does not contain any anomalous images. As a result, the adaptive threshold will take the value of the highest anomaly score observed in the normal validation images, which may lead to poor predictions. For a more reliable adaptive threshold computation, please add some anomalous images to the validation set.\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "model = AiVad()\n",
    "\n",
    "# Cell 6에서 설정한 engine과 datamodule 사용\n",
    "# Train using the engine\n",
    "engine.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd3db1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mt_p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
